"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[3546],{69553:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>r,default:()=>h,frontMatter:()=>i,metadata:()=>o,toc:()=>l});var s=t(85893),a=t(11151);const i={sidebar_label:"assistant_agent",title:"agentchat.assistant_agent"},r=void 0,o={id:"reference/agentchat/assistant_agent",title:"agentchat.assistant_agent",description:"AssistantAgent",source:"@site/docs/reference/agentchat/assistant_agent.md",sourceDirName:"reference/agentchat",slug:"/reference/agentchat/assistant_agent",permalink:"/autogen/docs/reference/agentchat/assistant_agent",draft:!1,unlisted:!1,editUrl:"https://github.com/microsoft/autogen/edit/main/website/docs/reference/agentchat/assistant_agent.md",tags:[],version:"current",frontMatter:{sidebar_label:"assistant_agent",title:"agentchat.assistant_agent"},sidebar:"referenceSideBar",previous:{title:"agent",permalink:"/autogen/docs/reference/agentchat/agent"},next:{title:"chat",permalink:"/autogen/docs/reference/agentchat/chat"}},c={},l=[{value:"AssistantAgent",id:"assistantagent",level:2},{value:"__init__",id:"__init__",level:3}];function d(e){const n={a:"a",code:"code",em:"em",h2:"h2",h3:"h3",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.a)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.h2,{id:"assistantagent",children:"AssistantAgent"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"class AssistantAgent(ConversableAgent)\n"})}),"\n",(0,s.jsx)(n.p,{children:"(In preview) Assistant agent, designed to solve a task with LLM."}),"\n",(0,s.jsxs)(n.p,{children:["AssistantAgent is a subclass of ConversableAgent configured with a default system message.\nThe default system message is designed to solve a task with LLM,\nincluding suggesting python code blocks and debugging.\n",(0,s.jsx)(n.code,{children:"human_input_mode"}),' is default to "NEVER"\nand ',(0,s.jsx)(n.code,{children:"code_execution_config"})," is default to False.\nThis agent doesn't execute code by default, and expects the user to execute the code."]}),"\n",(0,s.jsx)(n.h3,{id:"__init__",children:"__init__"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'def __init__(name: str,\n             system_message: Optional[str] = DEFAULT_SYSTEM_MESSAGE,\n             llm_config: Optional[Union[Dict, Literal[False]]] = None,\n             is_termination_msg: Optional[Callable[[Dict], bool]] = None,\n             max_consecutive_auto_reply: Optional[int] = None,\n             human_input_mode: Literal["ALWAYS", "NEVER",\n                                       "TERMINATE"] = "NEVER",\n             description: Optional[str] = None,\n             **kwargs)\n'})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Arguments"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"name"})," ",(0,s.jsx)(n.em,{children:"str"})," - agent name."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"system_message"})," ",(0,s.jsx)(n.em,{children:"str"})," - system message for the ChatCompletion inference.\nPlease override this attribute if you want to reprogram the agent."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"llm_config"})," ",(0,s.jsx)(n.em,{children:"dict or False or None"})," - llm inference configuration.\nPlease refer to ",(0,s.jsx)(n.a,{href:"/docs/reference/oai/client#create",children:"OpenAIWrapper.create"}),"\nfor available options."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"is_termination_msg"})," ",(0,s.jsx)(n.em,{children:"function"}),' - a function that takes a message in the form of a dictionary\nand returns a boolean value indicating if this received message is a termination message.\nThe dict can contain the following keys: "content", "role", "name", "function_call".']}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"max_consecutive_auto_reply"})," ",(0,s.jsx)(n.em,{children:"int"}),' - the maximum number of consecutive auto replies.\ndefault to None (no limit provided, class attribute MAX_CONSECUTIVE_AUTO_REPLY will be used as the limit in this case).\nThe limit only plays a role when human_input_mode is not "ALWAYS".']}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"**kwargs"})," ",(0,s.jsx)(n.em,{children:"dict"})," - Please refer to other kwargs in\n",(0,s.jsx)(n.a,{href:"conversable_agent#__init__",children:"ConversableAgent"}),"."]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,a.a)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},11151:(e,n,t)=>{t.d(n,{Z:()=>o,a:()=>r});var s=t(67294);const a={},i=s.createContext(a);function r(e){const n=s.useContext(i);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:r(e.components),s.createElement(i.Provider,{value:n},e.children)}}}]);