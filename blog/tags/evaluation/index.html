<!doctype html>
<html lang="en" dir="ltr" class="blog-wrapper blog-tags-post-list-page plugin-blog plugin-id-default" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.1.1">
<title data-rh="true">2 posts tagged with &quot;evaluation&quot; | AutoGen</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://microsoft.github.io/autogen/blog/tags/evaluation"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" property="og:title" content="2 posts tagged with &quot;evaluation&quot; | AutoGen"><meta data-rh="true" name="docusaurus_tag" content="blog_tags_posts"><meta data-rh="true" name="docsearch:docusaurus_tag" content="blog_tags_posts"><link data-rh="true" rel="icon" href="/autogen/img/ag.ico"><link data-rh="true" rel="canonical" href="https://microsoft.github.io/autogen/blog/tags/evaluation"><link data-rh="true" rel="alternate" href="https://microsoft.github.io/autogen/blog/tags/evaluation" hreflang="en"><link data-rh="true" rel="alternate" href="https://microsoft.github.io/autogen/blog/tags/evaluation" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/autogen/blog/rss.xml" title="AutoGen RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/autogen/blog/atom.xml" title="AutoGen Atom Feed">






<script>!function(e,t,n,c,s,a,r){e[n]=e[n]||function(){(e[n].q=e[n].q||[]).push(arguments)},(a=t.createElement(c)).async=1,a.src="https://www.clarity.ms/tag/lnxpe6skj1",(r=t.getElementsByTagName(c)[0]).parentNode.insertBefore(a,r)}(window,document,"clarity","script")</script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.css" integrity="sha384-Um5gpz1odJg5Z4HAmzPtgZKdTBHZdw8S29IecapCSB31ligYPhHQZMIlWLYQGVoc" crossorigin="anonymous">
<script src="/autogen/js/custom.js" async defer="defer"></script><link rel="stylesheet" href="/autogen/assets/css/styles.d8ef5d37.css">
<script src="/autogen/assets/js/runtime~main.33d2ca05.js" defer="defer"></script>
<script src="/autogen/assets/js/main.f5c79556.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const a=new URLSearchParams(window.location.search).entries();for(var[t,e]of a)if(t.startsWith("docusaurus-data-")){var n=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(n,e)}}catch(t){}}(),document.documentElement.setAttribute("data-announcement-bar-initially-dismissed",function(){try{return"true"===localStorage.getItem("docusaurus.announcement.dismiss")}catch(t){}return!1}())</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><div class="announcementBar_mb4j" style="background-color:#fafbfc;color:#091E42" role="banner"><div class="announcementBarPlaceholder_vyr4"></div><div class="content_knG7 announcementBarContent_xLdY">What's new in AutoGen? Read <a href="/autogen/blog/2024/03/03/AutoGen-Update">this blog</a> for an overview of updates</div><button type="button" aria-label="Close" class="clean-btn close closeButton_CVFx announcementBarClose_gvF7"><svg viewBox="0 0 15 15" width="14" height="14"><g stroke="currentColor" stroke-width="3.1"><path d="M.75.75l13.5 13.5M14.25.75L.75 14.25"></path></g></svg></button></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/autogen/"><div class="navbar__logo"><img src="/autogen/img/ag.svg" alt="AutoGen" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/autogen/img/ag.svg" alt="AutoGen" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">AutoGen</b></a><div class="navbar__item dropdown dropdown--hoverable"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">Docs</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/autogen/docs/Getting-Started">Getting Started</a></li><li><a class="dropdown__link" href="/autogen/docs/installation/">Installation</a></li><li><a class="dropdown__link" href="/autogen/docs/tutorial/introduction">Tutorial</a></li><li><a class="dropdown__link" href="/autogen/docs/topics">User Guide</a></li><li><a class="dropdown__link" href="/autogen/docs/reference/agentchat/conversable_agent">API Reference</a></li><li><a class="dropdown__link" href="/autogen/docs/FAQ">FAQs</a></li><li><a class="dropdown__link" href="/autogen/docs/autogen-studio/getting-started">AutoGen Studio</a></li><li><a class="dropdown__link" href="/autogen/docs/ecosystem">Ecosystem</a></li><li><a class="dropdown__link" href="/autogen/docs/contributor-guide/contributing">Contributor Guide</a></li><li><a class="dropdown__link" href="/autogen/docs/Research">Research</a></li></ul></div><div class="navbar__item dropdown dropdown--hoverable"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">Examples</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/autogen/docs/Examples">Examples by Category</a></li><li><a class="dropdown__link" href="/autogen/docs/notebooks">Examples by Notebook</a></li><li><a class="dropdown__link" href="/autogen/docs/Gallery">Application Gallery</a></li></ul></div><div class="navbar__item dropdown dropdown--hoverable"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">Other Languages</a><ul class="dropdown__menu"><li><a href="https://microsoft.github.io/autogen-for-net/" target="_blank" rel="noopener noreferrer" class="dropdown__link">Dotnet<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/autogen/blog">Blog</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/microsoft/autogen" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><a href="https://aka.ms/autogen-dc" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">Discord<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><a href="https://twitter.com/pyautogen" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">Twitter<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><div class="navbar__search searchBarContainer_NW3z"><input placeholder="Search" aria-label="Search" class="navbar__search-input"><div class="loadingRing_RJI3 searchBarLoadingRing_YnHq"><div></div><div></div><div></div><div></div></div><div class="searchHintContainer_Pkmr"><kbd class="searchHint_iIMx">ctrl</kbd><kbd class="searchHint_iIMx">K</kbd></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_re4s thin-scrollbar" aria-label="Blog recent posts navigation"><div class="sidebarItemTitle_pO2u margin-bottom--md">Recent posts</div><ul class="sidebarItemList_Yudw clean-list"><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/autogen/blog/2024/07/25/AgentOps">AgentOps, the Best Tool for AutoGen Agent Observability</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/autogen/blog/2024/06/24/AltModels-Classes">Enhanced Support for Non-OpenAI Models</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/autogen/blog/2024/06/21/AgentEval">AgentEval: A Developer Tool to Assess Utility of LLM-powered Applications</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/autogen/blog/2024/05/24/Agent">Agents in AutoGen</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/autogen/blog/2024/03/11/AutoDefense/Defending LLMs Against Jailbreak Attacks with AutoDefense">AutoDefense - Defend against jailbreak attacks with AutoGen</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/autogen/blog/2024/03/03/AutoGen-Update">What&#x27;s New in AutoGen?</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/autogen/blog/2024/02/29/StateFlow">StateFlow - Build State-Driven Workflows with Customized Speaker Selection in GroupChat</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/autogen/blog/2024/02/11/FSM-GroupChat">FSM Group Chat -- User-specified agent transitions</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/autogen/blog/2024/02/02/AutoAnny">Anny: Assisting AutoGen Devs Via AutoGen</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/autogen/blog/2024/01/26/Custom-Models">AutoGen with Custom Models: Empowering Users to Use Their Own Inference Mechanism</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/autogen/blog/2024/01/25/AutoGenBench">AutoGenBench -- A Tool for Measuring and Evaluating AutoGen Agents</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/autogen/blog/2024/01/23/Code-execution-in-docker">Code execution is now by default inside docker container</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/autogen/blog/2023/12/29/AgentDescriptions">All About Agent Descriptions</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/autogen/blog/2023/12/23/AgentOptimizer">AgentOptimizer - An Agentic Way to Train Your LLM Agent</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/autogen/blog/2023/12/01/AutoGenStudio">AutoGen Studio: Interactively Explore Multi-Agent Workflows</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/autogen/blog/2023/11/26/Agent-AutoBuild">Agent AutoBuild - Automatically Building Multi-agent Systems</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/autogen/blog/2023/11/20/AgentEval">How to Assess Utility of LLM-powered Applications?</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/autogen/blog/2023/11/13/OAI-assistants">AutoGen Meets GPTs</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/autogen/blog/2023/11/09/EcoAssistant">EcoAssistant - Using LLM Assistants More Accurately and Affordably</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/autogen/blog/2023/11/06/LMM-Agent">Multimodal with GPT-4V and LLaVA</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/autogen/blog/2023/10/26/TeachableAgent">AutoGen&#x27;s Teachable Agents</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/autogen/blog/2023/10/18/RetrieveChat">Retrieval-Augmented Generation (RAG) Applications with AutoGen</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/autogen/blog/2023/07/14/Local-LLMs">Use AutoGen for Local LLMs</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/autogen/blog/2023/06/28/MathChat">MathChat - An Conversational Framework to Solve Math Problems</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/autogen/blog/2023/05/18/GPT-adaptive-humaneval">Achieve More, Pay Less - Use GPT-4 Smartly</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/autogen/blog/2023/04/21/LLM-tuning-math">Does Model and Inference Parameter Matter in LLM Applications? - A Case Study for MATH</a></li></ul></nav></aside><main class="col col--7" itemscope="" itemtype="https://schema.org/Blog"><header class="margin-bottom--xl"><h1>2 posts tagged with &quot;evaluation&quot;</h1><a href="/autogen/blog/tags">View All Tags</a></header><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="https://schema.org/BlogPosting"><meta itemprop="description" content="Fig.1: An AgentEval framework with verification step"><header><h2 class="title_f1Hy" itemprop="headline"><a itemprop="url" href="/autogen/blog/2024/06/21/AgentEval">AgentEval: A Developer Tool to Assess Utility of LLM-powered Applications</a></h2><div class="container_mt6G margin-vert--md"><time datetime="2024-06-21T00:00:00.000Z" itemprop="datePublished">June 21, 2024</time> · <!-- -->7 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_Hf19"><div class="avatar margin-bottom--sm"><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/jluey1" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">James Woffinden-Luey</span></a></div><small class="avatar__subtitle" itemprop="description">Senior Research Engineer at Microsoft Research</small></div></div></div><div class="col col--6 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://github.com/julianakiseleva/" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="https://avatars.githubusercontent.com/u/5908392?v=4" alt="Julia Kiseleva" itemprop="image"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/julianakiseleva/" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Julia Kiseleva</span></a></div><small class="avatar__subtitle" itemprop="description">Senior Researcher at Microsoft Research</small></div></div></div></div></header><div class="markdown" itemprop="articleBody"><p><img decoding="async" loading="lazy" alt="Fig.1: An AgentEval framework with verification step" src="/autogen/assets/images/agenteval_ov_v3-c471c3a909d8046fc75e70fb198e63ac.png" width="1483" height="1206" class="img_ev3q"></p>
<p align="center"><em>Fig.1 illustrates the general flow of AgentEval with verification step </em></p>
<p>TL;DR:</p>
<ul>
<li>As a developer, how can you assess the utility and effectiveness of an LLM-powered application in helping end users with their tasks?</li>
<li>To shed light on the question above, we previously introduced <a href="https://microsoft.github.io/autogen/blog/2023/11/20/AgentEval/" target="_blank" rel="noopener noreferrer"><code>AgentEval</code></a> — a framework to assess the multi-dimensional utility of any LLM-powered application crafted to assist users in specific tasks. We have now embedded it as part of the AutoGen library to ease developer adoption.</li>
<li>Here, we introduce an updated version of AgentEval that includes a verification process to estimate the robustness of the QuantifierAgent. More details can be found in <a href="https://arxiv.org/abs/2405.02178" target="_blank" rel="noopener noreferrer">this paper</a>.</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="introduction">Introduction<a href="#introduction" class="hash-link" aria-label="Direct link to Introduction" title="Direct link to Introduction">​</a></h2>
<p>Previously introduced <a href="https://microsoft.github.io/autogen/blog/2023/11/20/AgentEval/" target="_blank" rel="noopener noreferrer"><code>AgentEval</code></a> is a comprehensive framework designed to bridge the gap in assessing the utility of LLM-powered applications. It leverages recent advancements in LLMs to offer a scalable and cost-effective alternative to traditional human evaluations. The framework comprises three main agents: <code>CriticAgent</code>, <code>QuantifierAgent</code>, and <code>VerifierAgent</code>, each playing a crucial role in assessing the task utility of an application.</p>
<p><strong>CriticAgent: Defining the Criteria</strong></p>
<p>The CriticAgent&#x27;s primary function is to suggest a set of criteria for evaluating an application based on the task description and examples of successful and failed executions. For instance, in the context of a math tutoring application, the CriticAgent might propose criteria such as efficiency, clarity, and correctness. These criteria are essential for understanding the various dimensions of the application&#x27;s performance. It’s highly recommended that application developers validate the suggested criteria leveraging their domain expertise.</p>
<p><strong>QuantifierAgent: Quantifying the Performance</strong></p>
<p>Once the criteria are established, the QuantifierAgent takes over to quantify how well the application performs against each criterion. This quantification process results in a multi-dimensional assessment of the application&#x27;s utility, providing a detailed view of its strengths and weaknesses.</p>
<p><strong>VerifierAgent: Ensuring Robustness and Relevance</strong></p>
<p>VerifierAgent ensures the criteria used to evaluate a utility are effective for the end-user, maintaining both robustness and high discriminative power. It does this through two main actions:</p>
<ol>
<li>
<p>Criteria Stability:</p>
<ul>
<li>Ensures criteria are essential, non-redundant, and consistently measurable.</li>
<li>Iterates over generating and quantifying criteria, eliminating redundancies, and evaluating their stability.</li>
<li>Retains only the most robust criteria.</li>
</ul>
</li>
<li>
<p>Discriminative Power:</p>
<ul>
<li>Tests the system&#x27;s reliability by introducing adversarial examples (noisy or compromised data).</li>
<li>Assesses the system&#x27;s ability to distinguish these from standard cases.</li>
<li>If the system fails, it indicates the need for better criteria to handle varied conditions effectively.</li>
</ul>
</li>
</ol>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="a-flexible-and-scalable-framework">A Flexible and Scalable Framework<a href="#a-flexible-and-scalable-framework" class="hash-link" aria-label="Direct link to A Flexible and Scalable Framework" title="Direct link to A Flexible and Scalable Framework">​</a></h2>
<p>One of AgentEval&#x27;s key strengths is its flexibility. It can be applied to a wide range of tasks where success may or may not be clearly defined. For tasks with well-defined success criteria, such as household chores, the framework can evaluate whether multiple successful solutions exist and how they compare. For more open-ended tasks, such as generating an email template, AgentEval can assess the utility of the system&#x27;s suggestions.</p>
<p>Furthermore, AgentEval allows for the incorporation of human expertise. Domain experts can participate in the evaluation process by suggesting relevant criteria or verifying the usefulness of the criteria identified by the agents. This human-in-the-loop approach ensures that the evaluation remains grounded in practical, real-world considerations.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="empirical-validation">Empirical Validation<a href="#empirical-validation" class="hash-link" aria-label="Direct link to Empirical Validation" title="Direct link to Empirical Validation">​</a></h2>
<p>To validate AgentEval, the framework was tested on two applications: math problem solving and ALFWorld, a household task simulation. The math dataset comprised 12,500 challenging problems, each with step-by-step solutions, while the ALFWorld dataset involved multi-turn interactions in a simulated environment. In both cases, AgentEval successfully identified relevant criteria, quantified performance, and verified the robustness of the evaluations, demonstrating its effectiveness and versatility.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="how-to-use-agenteval">How to use <code>AgentEval</code><a href="#how-to-use-agenteval" class="hash-link" aria-label="Direct link to how-to-use-agenteval" title="Direct link to how-to-use-agenteval">​</a></h2>
<p>AgentEval currently has two main stages; criteria generation and criteria quantification (criteria verification is still under development). Both stages make use of sequential LLM-powered agents to make their determinations.</p>
<p><strong>Criteria Generation:</strong></p>
<p>During criteria generation, AgentEval uses example execution message chains to create a set of criteria for quantifying how well an application performed for a given task.</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">def generate_criteria(</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    llm_config: Optional[Union[Dict, Literal[False]]] = None,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    task: Task = None,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    additional_instructions: str = &quot;&quot;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    max_round=2,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    use_subcritic: bool = False,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Parameters:</p>
<ul>
<li>llm_config (dict or bool): llm inference configuration.</li>
<li>task (<a href="https://github.com/microsoft/autogen/tree/main/autogen/agentchat/contrib/agent_eval/task.py" target="_blank" rel="noopener noreferrer">Task</a>): The task to evaluate.</li>
<li>additional_instructions (str, optional): Additional instructions for the criteria agent.</li>
<li>max_round (int, optional): The maximum number of rounds to run the conversation.</li>
<li>use_subcritic (bool, optional): Whether to use the Subcritic agent to generate subcriteria. The Subcritic agent will break down a generated criteria into smaller criteria to be assessed.</li>
</ul>
<p>Example code:</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">config_list = autogen.config_list_from_json(&quot;OAI_CONFIG_LIST&quot;)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">task = Task(</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    **{</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        &quot;name&quot;: &quot;Math problem solving&quot;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        &quot;description&quot;: &quot;Given any question, the system needs to solve the problem as consisely and accurately as possible&quot;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        &quot;successful_response&quot;: response_successful,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        &quot;failed_response&quot;: response_failed,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">criteria = generate_criteria(task=task, llm_config={&quot;config_list&quot;: config_list})</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Note: Only one sample execution chain (success/failure) is required for the task object but AgentEval will perform better with an example for each case.</p>
<p>Example Output:</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">[</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        &quot;name&quot;: &quot;Accuracy&quot;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        &quot;description&quot;: &quot;The solution must be correct and adhere strictly to mathematical principles and techniques appropriate for the problem.&quot;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        &quot;accepted_values&quot;: [&quot;Correct&quot;, &quot;Minor errors&quot;, &quot;Major errors&quot;, &quot;Incorrect&quot;]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    },</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        &quot;name&quot;: &quot;Conciseness&quot;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        &quot;description&quot;: &quot;The explanation and method provided should be direct and to the point, avoiding unnecessary steps or complexity.&quot;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        &quot;accepted_values&quot;: [&quot;Very concise&quot;, &quot;Concise&quot;, &quot;Somewhat verbose&quot;, &quot;Verbose&quot;]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    },</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        &quot;name&quot;: &quot;Relevance&quot;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        &quot;description&quot;: &quot;The content of the response must be relevant to the question posed and should address the specific problem requirements.&quot;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        &quot;accepted_values&quot;: [&quot;Highly relevant&quot;, &quot;Relevant&quot;, &quot;Somewhat relevant&quot;, &quot;Not relevant&quot;]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">]</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p><strong>Criteria Quantification:</strong></p>
<p>During the quantification stage, AgentEval will use the generated criteria (or user defined criteria) to assess a given execution chain to determine how well the application performed.</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">def quantify_criteria(</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    llm_config: Optional[Union[Dict, Literal[False]]],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    criteria: List[Criterion],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    task: Task,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    test_case: str,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    ground_truth: str,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Parameters:</p>
<ul>
<li>llm_config (dict or bool): llm inference configuration.</li>
<li>criteria (<a href="https://github.com/microsoft/autogen/tree/main/autogen/agentchat/contrib/agent_eval/criterion.py" target="_blank" rel="noopener noreferrer">Criterion</a>): A list of criteria for evaluating the utility of a given task. This can either be generated by the <code>generate_criteria</code> function or manually created.</li>
<li>task (<a href="https://github.com/microsoft/autogen/tree/main/autogen/agentchat/contrib/agent_eval/task.py" target="_blank" rel="noopener noreferrer">Task</a>): The task to evaluate. It should match the one used during the <code>generate_criteria</code> step.</li>
<li>test_case (str): The execution chain to assess. Typically this is a json list of messages but could be any string representation of a conversation chain.</li>
<li>ground_truth (str): The ground truth for the test case.</li>
</ul>
<p>Example Code:</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">test_case=&quot;&quot;&quot;[</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">      &quot;content&quot;: &quot;Find $24^{-1} \\pmod{11^2}$. That is, find the residue $b$ for which $24b \\equiv 1\\pmod{11^2}$.\n\nExpress your answer as an integer from $0$ to $11^2-1$, inclusive.&quot;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">      &quot;role&quot;: &quot;user&quot;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    },</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">      &quot;content&quot;: &quot;To find the modular inverse of 24 modulo 11^2, we can use the Extended Euclidean Algorithm. Here is a Python function to compute the modular inverse using this algorithm:\n\n```python\ndef mod_inverse(a, m):\n...&quot;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">      &quot;role&quot;: &quot;assistant&quot;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  ]&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">quantifier_output = quantify_criteria(</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    llm_config={&quot;config_list&quot;: config_list},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    criteria=criteria,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    task=task,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    test_case=test_case,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    ground_truth=&quot;true&quot;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>The output will be a json object consisting of the ground truth and a dictionary mapping each criteria to it&#x27;s score.</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">{</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  &quot;actual_success&quot;: true,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  &quot;estimated_performance&quot;: {</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">      &quot;Accuracy&quot;: &quot;Correct&quot;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">      &quot;Conciseness&quot;: &quot;Concise&quot;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">      &quot;Relevance&quot;: &quot;Highly relevant&quot;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="what-is-next">What is next?<a href="#what-is-next" class="hash-link" aria-label="Direct link to What is next?" title="Direct link to What is next?">​</a></h2>
<ul>
<li>Enabling AgentEval in AutoGen Studio for a nocode solution.</li>
<li>Fully implementing VerifierAgent in the AgentEval framework.</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="conclusion">Conclusion<a href="#conclusion" class="hash-link" aria-label="Direct link to Conclusion" title="Direct link to Conclusion">​</a></h2>
<p>AgentEval represents a significant advancement in the evaluation of LLM-powered applications. By combining the strengths of CriticAgent, QuantifierAgent, and VerifierAgent, the framework offers a robust, scalable, and flexible solution for assessing task utility. This innovative approach not only helps developers understand the current performance of their applications but also provides valuable insights that can drive future improvements. As the field of intelligent agents continues to evolve, frameworks like AgentEval will play a crucial role in ensuring that these applications meet the diverse and dynamic needs of their users.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="further-reading">Further reading<a href="#further-reading" class="hash-link" aria-label="Direct link to Further reading" title="Direct link to Further reading">​</a></h2>
<p>Please refer to our <a href="https://arxiv.org/abs/2405.02178" target="_blank" rel="noopener noreferrer">paper</a> and <a href="https://github.com/microsoft/autogen/tree/main/autogen/agentchat/contrib/agent_eval" target="_blank" rel="noopener noreferrer">codebase</a> for more details about AgentEval.</p>
<p>If you find this blog useful, please consider citing:</p>
<div class="language-bobtex codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bobtex codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">@article{arabzadeh2024assessing,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  title={Assessing and Verifying Task Utility in LLM-Powered Applications},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  author={Arabzadeh, Negar and Huo, Siging and Mehta, Nikhil and Wu, Qinqyun and Wang, Chi and Awadallah, Ahmed and Clarke, Charles LA and Kiseleva, Julia},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  journal={arXiv preprint arXiv:2405.02178},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  year={2024}</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div><footer class="row docusaurus-mt-lg"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/autogen/blog/tags/llm">LLM</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/autogen/blog/tags/gpt">GPT</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/autogen/blog/tags/evaluation">evaluation</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/autogen/blog/tags/task-utility">task utility</a></li></ul></div></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="https://schema.org/BlogPosting"><meta itemprop="description" content="Fig.1: A verification framework"><header><h2 class="title_f1Hy" itemprop="headline"><a itemprop="url" href="/autogen/blog/2023/11/20/AgentEval">How to Assess Utility of LLM-powered Applications?</a></h2><div class="container_mt6G margin-vert--md"><time datetime="2023-11-20T00:00:00.000Z" itemprop="datePublished">November 20, 2023</time> · <!-- -->10 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://github.com/julianakiseleva/" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="https://avatars.githubusercontent.com/u/5908392?v=4" alt="Julia Kiseleva" itemprop="image"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/julianakiseleva/" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Julia Kiseleva</span></a></div><small class="avatar__subtitle" itemprop="description">Senior Researcher at Microsoft Research</small></div></div></div><div class="col col--6 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://www.negara.me/" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="https://github.com/Narabzad.png" alt="Negar Arabzadeh" itemprop="image"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://www.negara.me/" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Negar Arabzadeh</span></a></div><small class="avatar__subtitle" itemprop="description">PhD student at the University of Waterloo</small></div></div></div></div></header><div class="markdown" itemprop="articleBody"><p><img decoding="async" loading="lazy" alt="Fig.1: A verification framework" src="/autogen/assets/images/agenteval-CQ-59f82d98878045817d02a3915839a92a.png" width="3142" height="640" class="img_ev3q"></p>
<p align="center"><em>Fig.1 illustrates the general flow of AgentEval</em></p>
<p><strong>TL;DR:</strong></p>
<ul>
<li>As a developer of an LLM-powered application, how can you assess the utility it brings to end users while helping them with their tasks?</li>
<li>To shed light on the question above, we introduce <code>AgentEval</code> — the first version of the framework to assess the utility of any LLM-powered application crafted to assist users in specific tasks.  AgentEval aims to simplify the evaluation process by automatically proposing a set of criteria tailored to the unique purpose of your application. This allows for a comprehensive assessment, quantifying the utility of your application against the suggested criteria.</li>
<li>We demonstrate how <code>AgentEval</code> work using <a href="https://microsoft.github.io/autogen/blog/2023/06/28/MathChat" target="_blank" rel="noopener noreferrer">math problems dataset</a> as an example in the <a href="https://github.com/microsoft/autogen/blob/main/notebook/agenteval_cq_math.ipynb" target="_blank" rel="noopener noreferrer">following notebook</a>. Any feedback would be useful for future development. Please contact us on our <a href="http://aka.ms/autogen-dc" target="_blank" rel="noopener noreferrer">Discord</a>.</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="introduction">Introduction<a href="#introduction" class="hash-link" aria-label="Direct link to Introduction" title="Direct link to Introduction">​</a></h2>
<p>AutoGen aims to simplify the development of LLM-powered multi-agent systems for various applications, ultimately making end users&#x27; lives easier by assisting with their tasks. Next, we all yearn to understand how our developed systems perform, their utility for users, and, perhaps most crucially, how we can enhance them. Directly evaluating multi-agent systems poses challenges as current approaches predominantly rely on success metrics – essentially, whether the agent accomplishes tasks. However, comprehending user interaction with a system involves far more than success alone. Take math problems, for instance; it&#x27;s not merely about the agent solving the problem. Equally significant is its ability to convey solutions based on various criteria, including completeness, conciseness, and the clarity of the provided explanation. Furthermore, success isn&#x27;t always clearly defined for every task.</p>
<p>Rapid advances in LLMs and multi-agent systems have brought forth many emerging capabilities that we&#x27;re keen on translating into tangible utilities for end users. We introduce the first version of <code>AgentEval</code> framework - a tool crafted to empower developers in swiftly gauging the utility of LLM-powered applications designed to help end users accomplish the desired task.</p>
<p><img decoding="async" loading="lazy" alt="Fig.2: An overview of the tasks taxonomy" src="/autogen/assets/images/tasks-taxonomy-c4b7c6fe465e12dddde9235c3ee8c281.png" width="1954" height="1111" class="img_ev3q">
</p><p align="center"><em>Fig. 2 provides  an overview of the tasks taxonomy</em></p><p></p>
<p>Let&#x27;s first look into an overview of the suggested task taxonomy that a multi-agent system can be designed for. In general, the tasks can be split into two types, where:</p>
<ul>
<li><em>Success is not clearly defined</em> - refer to instances when users utilize a system in an assistive manner, seeking suggestions rather than expecting the system to solve the task. For example, a user might request the system to generate an email. In many cases, this generated content serves as a template that the user will later edit. However, defining success precisely for such tasks is relatively complex.</li>
<li><em>Success is clearly defined</em> - refer to instances where we can clearly define whether a system solved the task or not. Consider agents that assist in accomplishing household tasks, where the definition of success is clear and measurable. This category can be further divided into two separate subcategories:<!-- -->
<ul>
<li><em>The optimal solution exits</em> - these are tasks where only one solution is possible. For example, if you ask your assistant to turn on the light, the success of this task is clearly defined, and there is only one way to accomplish it.</li>
<li><em>Multiple solutions exist</em> - increasingly, we observe situations where multiple trajectories of agent behavior can lead to either success or failure. In such cases, it is crucial to differentiate between the various successful and unsuccessful trajectories. For example, when you ask the agent to suggest you a food recipe or tell you a joke.</li>
</ul>
</li>
</ul>
<p>In our <code>AgentEval</code> framework, we are currently focusing on tasks where <em>Success is clearly defined</em>. Next, we will introduce the suggested framework.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="agenteval-framework"><code>AgentEval</code> Framework<a href="#agenteval-framework" class="hash-link" aria-label="Direct link to agenteval-framework" title="Direct link to agenteval-framework">​</a></h2>
<p>Our previous research on <a href="https://github.com/microsoft/iglu-datasets" target="_blank" rel="noopener noreferrer">assistive agents in Minecraft</a> suggested that the most optimal way to obtain human judgments is to present humans with two agents side by side and ask for preferences. In this setup of pairwise comparison, humans can develop criteria to explain why they prefer the behavior of one agent over another. For instance, <em>&#x27;the first agent was faster in execution,&#x27;</em> or <em>&#x27;the second agent moves more naturally.&#x27;</em> So, the comparative nature led humans to come up with a list of criteria that helps to infer the utility of the task. With this idea in mind, we designed <code>AgentEval</code> (shown in Fig. 1), where we employ LLMs to help us understand, verify, and assess task <em>utility</em> for the multi-agent system. Namely:</p>
<ul>
<li>The goal of <code>CriticAgent</code> is to suggest the list of criteria (Fig. 1), that can be used to assess task utility. This is an example of how <code>CriticAgent</code> is defined using <code>Autogen</code>:</li>
</ul>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">critic </span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain"> autogen</span><span class="token punctuation" style="color:rgb(199, 146, 234)">.</span><span class="token plain">AssistantAgent</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    name</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token string" style="color:rgb(195, 232, 141)">&quot;critic&quot;</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    llm_config</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token punctuation" style="color:rgb(199, 146, 234)">{</span><span class="token string" style="color:rgb(195, 232, 141)">&quot;config_list&quot;</span><span class="token punctuation" style="color:rgb(199, 146, 234)">:</span><span class="token plain"> config_list</span><span class="token punctuation" style="color:rgb(199, 146, 234)">}</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    system_message</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token triple-quoted-string string" style="color:rgb(195, 232, 141)">&quot;&quot;&quot;You are a helpful assistant. You suggest criteria for evaluating different tasks. They should be distinguishable, quantifiable, and not redundant.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token triple-quoted-string string" style="color:rgb(195, 232, 141)">    Convert the evaluation criteria into a dictionary where the keys are the criteria.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token triple-quoted-string string" style="color:rgb(195, 232, 141)">    The value of each key is a dictionary as follows {&quot;description&quot;: criteria description, &quot;accepted_values&quot;: possible accepted inputs for this key}</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token triple-quoted-string string" style="color:rgb(195, 232, 141)">    Make sure the keys are criteria for assessing the given task. &quot;accepted_values&quot; include the acceptable inputs for each key that are fine-grained and preferably multi-graded levels. &quot;description&quot; includes the criterion description.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token triple-quoted-string string" style="color:rgb(195, 232, 141)">    Return only the dictionary.&quot;&quot;&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Next, the critic is given successful and failed examples of the task execution; then, it is able to return a list of criteria (Fig. 1). For reference, use the <a href="https://github.com/microsoft/autogen/blob/main/notebook/agenteval_cq_math.ipynb" target="_blank" rel="noopener noreferrer">following notebook</a>.</p>
<ul>
<li>The goal of <code>QuantifierAgent</code> is to quantify each of the suggested criteria (Fig. 1), providing us with an idea of the utility of this system for the given task. Here is an example of how it can be defined:</li>
</ul>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">quantifier </span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain"> autogen</span><span class="token punctuation" style="color:rgb(199, 146, 234)">.</span><span class="token plain">AssistantAgent</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    name</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token string" style="color:rgb(195, 232, 141)">&quot;quantifier&quot;</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    llm_config</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token punctuation" style="color:rgb(199, 146, 234)">{</span><span class="token string" style="color:rgb(195, 232, 141)">&quot;config_list&quot;</span><span class="token punctuation" style="color:rgb(199, 146, 234)">:</span><span class="token plain"> config_list</span><span class="token punctuation" style="color:rgb(199, 146, 234)">}</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    system_message </span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain"> </span><span class="token triple-quoted-string string" style="color:rgb(195, 232, 141)">&quot;&quot;&quot;You are a helpful assistant. You quantify the output of different tasks based on the given criteria.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token triple-quoted-string string" style="color:rgb(195, 232, 141)">    The criterion is given in a dictionary format where each key is a distinct criteria.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token triple-quoted-string string" style="color:rgb(195, 232, 141)">    The value of each key is a dictionary as follows {&quot;description&quot;: criteria description , &quot;accepted_values&quot;: possible accepted inputs for this key}</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token triple-quoted-string string" style="color:rgb(195, 232, 141)">    You are going to quantify each of the criteria for a given task based on the task description.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token triple-quoted-string string" style="color:rgb(195, 232, 141)">    Return a dictionary where the keys are the criteria and the values are the assessed performance based on accepted values for each criteria.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token triple-quoted-string string" style="color:rgb(195, 232, 141)">    Return only the dictionary.&quot;&quot;&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="agenteval-results-based-on-math-problems-dataset"><code>AgentEval</code> Results based on Math Problems Dataset<a href="#agenteval-results-based-on-math-problems-dataset" class="hash-link" aria-label="Direct link to agenteval-results-based-on-math-problems-dataset" title="Direct link to agenteval-results-based-on-math-problems-dataset">​</a></h2>
<p>As an example, after running CriticAgent, we obtained the following criteria to verify the results for math problem dataset:</p>
<table><thead><tr><th>Criteria</th><th>Description</th><th>Accepted Values</th></tr></thead><tbody><tr><td>Problem Interpretation</td><td>Ability to correctly interpret the problem</td><td>[&quot;completely off&quot;, &quot;slightly relevant&quot;, &quot;relevant&quot;, &quot;mostly accurate&quot;, &quot;completely accurate&quot;]</td></tr><tr><td>Mathematical Methodology</td><td>Adequacy of the chosen mathematical or algorithmic methodology for the question</td><td>[&quot;inappropriate&quot;, &quot;barely adequate&quot;, &quot;adequate&quot;, &quot;mostly effective&quot;, &quot;completely effective&quot;]</td></tr><tr><td>Calculation Correctness</td><td>Accuracy of calculations made and solutions given</td><td>[&quot;completely incorrect&quot;, &quot;mostly incorrect&quot;, &quot;neither&quot;, &quot;mostly correct&quot;, &quot;completely correct&quot;]</td></tr><tr><td>Explanation Clarity</td><td>Clarity and comprehensibility of explanations, including language use and structure</td><td>[&quot;not at all clear&quot;, &quot;slightly clear&quot;, &quot;moderately clear&quot;, &quot;very clear&quot;, &quot;completely clear&quot;]</td></tr><tr><td>Code Efficiency</td><td>Quality of code in terms of efficiency and elegance</td><td>[&quot;not at all efficient&quot;, &quot;slightly efficient&quot;, &quot;moderately efficient&quot;, &quot;very efficient&quot;, &quot;extremely efficient&quot;]</td></tr><tr><td>Code Correctness</td><td>Correctness of the provided code</td><td>[&quot;completely incorrect&quot;, &quot;mostly incorrect&quot;, &quot;partly correct&quot;, &quot;mostly correct&quot;, &quot;completely correct&quot;]</td></tr></tbody></table>
<p>Then, after running QuantifierAgent, we obtained the results presented in Fig. 3, where you can see three models:</p>
<ul>
<li>AgentChat</li>
<li>ReAct</li>
<li>GPT-4 Vanilla Solver</li>
</ul>
<p>Lighter colors represent estimates for failed cases, and brighter colors show how discovered criteria were quantified.</p>
<p><img decoding="async" loading="lazy" alt="Fig.3: Results based on overall math problems dataset _s stands for successful cases, _f - stands for failed cases" src="/autogen/assets/images/math-problems-plot-03ec81b957c85db6ad9b1da353784b96.png" width="1200" height="800" class="img_ev3q">
</p><p align="center"><em>Fig.3 presents results based on overall math problems dataset <code>_s</code> stands for successful cases, <code>_f</code> - stands for failed cases</em></p><p></p>
<p>We note that while applying agentEval to math problems, the agent was not exposed to any ground truth information about the problem. As such, this figure illustrates an estimated performance of the three different agents, namely, Autogen (blue), Gpt-4 (red), and ReAct (green). We observe that by comparing the performance of any of the three agents in successful cases (dark bars of any color) versus unsuccessful cases (lighter version of the same bar), we note that AgentEval was able to assign higher quantification to successful cases than that of failed ones. This observation verifies AgentEval&#x27;s ability for task utility prediction. Additionally, AgentEval allows us to go beyond just a binary definition of success, enabling a more in-depth comparison between successful and failed cases.</p>
<p>It&#x27;s important not only to identify what is not working but also to recognize what and why actually went well.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="limitations-and-future-work">Limitations and Future Work<a href="#limitations-and-future-work" class="hash-link" aria-label="Direct link to Limitations and Future Work" title="Direct link to Limitations and Future Work">​</a></h2>
<p>The current implementation of <code>AgentEval</code> has a number of limitations which are planning to overcome in the future:</p>
<ul>
<li>The list of criteria varies per run (unless you store a seed). We would recommend to run <code>CriticAgent</code> at least two times, and pick criteria you think is important for your domain.</li>
<li>The results of the <code>QuantifierAgent</code> can vary with each run, so we recommend conducting multiple runs to observe the extent of result variations.</li>
</ul>
<p>To mitigate the limitations mentioned above, we are working on VerifierAgent, whose goal is to stabilize the results and provide additional explanations.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="summary">Summary<a href="#summary" class="hash-link" aria-label="Direct link to Summary" title="Direct link to Summary">​</a></h2>
<p><code>CriticAgent</code> and <code>QuantifierAgent</code> can be applied to the logs of any type of application, providing you with an in-depth understanding of the utility your solution brings to the user for a given task.</p>
<p>We would love to hear about how AgentEval works for your application. Any feedback would be useful for future development. Please contact us on our <a href="http://aka.ms/autogen-dc" target="_blank" rel="noopener noreferrer">Discord</a>.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="previous-research">Previous Research<a href="#previous-research" class="hash-link" aria-label="Direct link to Previous Research" title="Direct link to Previous Research">​</a></h2>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">@InProceedings{pmlr-v176-kiseleva22a,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  title = &quot;Interactive Grounded Language Understanding in a Collaborative Environment: IGLU 2021&quot;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  author = &quot;Kiseleva, Julia and Li, Ziming and Aliannejadi, Mohammad and Mohanty, Shrestha and ter Hoeve, Maartje and Burtsev, Mikhail and Skrynnik, Alexey and Zholus, Artem and Panov, Aleksandr and Srinet, Kavya and Szlam, Arthur and Sun, Yuxuan and Hofmann, Katja and C{\^o}t{\&#x27;e}, Marc-Alexandre and Awadallah, Ahmed and Abdrazakov, Linar and Churin, Igor and Manggala, Putra and Naszadi, Kata and van der Meer, Michiel and Kim, Taewoon&quot;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  booktitle = &quot;Proceedings of the NeurIPS 2021 Competitions and Demonstrations Track&quot;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  pages = &quot;146--161&quot;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  year = 2022,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  editor = &quot;Kiela, Douwe and Ciccone, Marco and Caputo, Barbara&quot;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  volume = 176,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  series = &quot;Proceedings of Machine Learning Research&quot;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  month = &quot;06--14 Dec&quot;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  publisher = &quot;PMLR&quot;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  pdf = 	 {https://proceedings.mlr.press/v176/kiseleva22a/kiseleva22a.pdf},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  url = 	 {https://proceedings.mlr.press/v176/kiseleva22a.html}.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">@InProceedings{pmlr-v220-kiseleva22a,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  title = &quot;Interactive Grounded Language Understanding in a Collaborative Environment: Retrospective on Iglu 2022 Competition&quot;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  author = &quot;Kiseleva, Julia and Skrynnik, Alexey and Zholus, Artem and Mohanty, Shrestha and Arabzadeh, Negar and C\^{o}t\&#x27;e, Marc-Alexandre and Aliannejadi, Mohammad and Teruel, Milagro and Li, Ziming and Burtsev, Mikhail and ter Hoeve, Maartje and Volovikova, Zoya and Panov, Aleksandr and Sun, Yuxuan and Srinet, Kavya and Szlam, Arthur and Awadallah, Ahmed and Rho, Seungeun and Kwon, Taehwan and Wontae Nam, Daniel and Bivort Haiek, Felipe and Zhang, Edwin and Abdrazakov, Linar and Qingyam, Guo and Zhang, Jason and Guo, Zhibin&quot;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  booktitle = &quot;Proceedings of the NeurIPS 2022 Competitions Track&quot;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  pages = &quot;204--216&quot;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  year = 2022,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  editor = &quot;Ciccone, Marco and Stolovitzky, Gustavo and Albrecht, Jacob&quot;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  volume = 220,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  series = &quot;Proceedings of Machine Learning Research&quot;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  month = &quot;28 Nov--09 Dec&quot;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  publisher = &quot;PMLR&quot;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  pdf = &quot;https://proceedings.mlr.press/v220/kiseleva22a/kiseleva22a.pdf&quot;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  url = &quot;https://proceedings.mlr.press/v220/kiseleva22a.html&quot;.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div><footer class="row docusaurus-mt-lg"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/autogen/blog/tags/llm">LLM</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/autogen/blog/tags/gpt">GPT</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/autogen/blog/tags/evaluation">evaluation</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/autogen/blog/tags/task-utility">task utility</a></li></ul></div></footer></article><nav class="pagination-nav" aria-label="Blog list page navigation"></nav></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://aka.ms/autogen-dc" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://twitter.com/pyautogen" target="_blank" rel="noopener noreferrer" class="footer__link-item">Twitter<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2024 AutoGen Authors |  <a target="_blank" style="color:#10adff" href="https://go.microsoft.com/fwlink/?LinkId=521839">Privacy and Cookies</a></div></div></div></footer></div>
</body>
</html>