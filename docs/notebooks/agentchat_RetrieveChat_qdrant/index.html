<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-notebooks/agentchat_RetrieveChat_qdrant" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.1.1">
<title data-rh="true">Using RetrieveChat with Qdrant for Retrieve Augmented Code Generation and Question Answering | AutoGen</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://microsoft.github.io/autogen/docs/notebooks/agentchat_RetrieveChat_qdrant"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Using RetrieveChat with Qdrant for Retrieve Augmented Code Generation and Question Answering | AutoGen"><meta data-rh="true" name="description" content="This notebook demonstrates the usage of QdrantRetrieveUserProxyAgent for RAG."><meta data-rh="true" property="og:description" content="This notebook demonstrates the usage of QdrantRetrieveUserProxyAgent for RAG."><link data-rh="true" rel="icon" href="/autogen/img/ag.ico"><link data-rh="true" rel="canonical" href="https://microsoft.github.io/autogen/docs/notebooks/agentchat_RetrieveChat_qdrant"><link data-rh="true" rel="alternate" href="https://microsoft.github.io/autogen/docs/notebooks/agentchat_RetrieveChat_qdrant" hreflang="en"><link data-rh="true" rel="alternate" href="https://microsoft.github.io/autogen/docs/notebooks/agentchat_RetrieveChat_qdrant" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/autogen/blog/rss.xml" title="AutoGen RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/autogen/blog/atom.xml" title="AutoGen Atom Feed">






<script>!function(e,t,n,c,s,a,r){e[n]=e[n]||function(){(e[n].q=e[n].q||[]).push(arguments)},(a=t.createElement(c)).async=1,a.src="https://www.clarity.ms/tag/lnxpe6skj1",(r=t.getElementsByTagName(c)[0]).parentNode.insertBefore(a,r)}(window,document,"clarity","script")</script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.css" integrity="sha384-Um5gpz1odJg5Z4HAmzPtgZKdTBHZdw8S29IecapCSB31ligYPhHQZMIlWLYQGVoc" crossorigin="anonymous">
<script src="/autogen/js/custom.js" async defer="defer"></script><link rel="stylesheet" href="/autogen/assets/css/styles.d8ef5d37.css">
<script src="/autogen/assets/js/runtime~main.33d2ca05.js" defer="defer"></script>
<script src="/autogen/assets/js/main.f5c79556.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const a=new URLSearchParams(window.location.search).entries();for(var[t,e]of a)if(t.startsWith("docusaurus-data-")){var n=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(n,e)}}catch(t){}}(),document.documentElement.setAttribute("data-announcement-bar-initially-dismissed",function(){try{return"true"===localStorage.getItem("docusaurus.announcement.dismiss")}catch(t){}return!1}())</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><div class="announcementBar_mb4j" style="background-color:#fafbfc;color:#091E42" role="banner"><div class="announcementBarPlaceholder_vyr4"></div><div class="content_knG7 announcementBarContent_xLdY">What's new in AutoGen? Read <a href="/autogen/blog/2024/03/03/AutoGen-Update">this blog</a> for an overview of updates</div><button type="button" aria-label="Close" class="clean-btn close closeButton_CVFx announcementBarClose_gvF7"><svg viewBox="0 0 15 15" width="14" height="14"><g stroke="currentColor" stroke-width="3.1"><path d="M.75.75l13.5 13.5M14.25.75L.75 14.25"></path></g></svg></button></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/autogen/"><div class="navbar__logo"><img src="/autogen/img/ag.svg" alt="AutoGen" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/autogen/img/ag.svg" alt="AutoGen" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">AutoGen</b></a><div class="navbar__item dropdown dropdown--hoverable"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">Docs</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/autogen/docs/Getting-Started">Getting Started</a></li><li><a class="dropdown__link" href="/autogen/docs/installation/">Installation</a></li><li><a class="dropdown__link" href="/autogen/docs/tutorial/introduction">Tutorial</a></li><li><a class="dropdown__link" href="/autogen/docs/topics">User Guide</a></li><li><a class="dropdown__link" href="/autogen/docs/reference/agentchat/conversable_agent">API Reference</a></li><li><a class="dropdown__link" href="/autogen/docs/FAQ">FAQs</a></li><li><a class="dropdown__link" href="/autogen/docs/autogen-studio/getting-started">AutoGen Studio</a></li><li><a class="dropdown__link" href="/autogen/docs/ecosystem">Ecosystem</a></li><li><a class="dropdown__link" href="/autogen/docs/contributor-guide/contributing">Contributor Guide</a></li><li><a class="dropdown__link" href="/autogen/docs/Research">Research</a></li></ul></div><div class="navbar__item dropdown dropdown--hoverable"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">Examples</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/autogen/docs/Examples">Examples by Category</a></li><li><a aria-current="page" class="dropdown__link dropdown__link--active" href="/autogen/docs/notebooks">Examples by Notebook</a></li><li><a class="dropdown__link" href="/autogen/docs/Gallery">Application Gallery</a></li></ul></div><div class="navbar__item dropdown dropdown--hoverable"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">Other Languages</a><ul class="dropdown__menu"><li><a href="https://microsoft.github.io/autogen-for-net/" target="_blank" rel="noopener noreferrer" class="dropdown__link">Dotnet<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><a class="navbar__item navbar__link" href="/autogen/blog">Blog</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/microsoft/autogen" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><a href="https://aka.ms/autogen-dc" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">Discord<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><a href="https://twitter.com/pyautogen" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">Twitter<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><div class="navbar__search searchBarContainer_NW3z"><input placeholder="Search" aria-label="Search" class="navbar__search-input"><div class="loadingRing_RJI3 searchBarLoadingRing_YnHq"><div></div><div></div><div></div><div></div></div><div class="searchHintContainer_Pkmr"><kbd class="searchHint_iIMx">ctrl</kbd><kbd class="searchHint_iIMx">K</kbd></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG menuWithAnnouncementBar_GW3s"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" aria-expanded="true" href="/autogen/docs/notebooks">Notebooks</a><button aria-label="Collapse sidebar category &#x27;Notebooks&#x27;" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/autogen/docs/notebooks/JSON_mode_example">Mitigating Prompt hacking with JSON Mode in Autogen</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/autogen/docs/notebooks/agentchat_RetrieveChat">Using RetrieveChat for Retrieve Augmented Code Generation and Question Answering</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/autogen/docs/notebooks/agentchat_RetrieveChat_mongodb">Using RetrieveChat Powered by MongoDB Atlas for Retrieve Augmented Code Generation and Question Answering</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/autogen/docs/notebooks/agentchat_RetrieveChat_pgvector">Using RetrieveChat Powered by PGVector for Retrieve Augmented Code Generation and Question Answering</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/autogen/docs/notebooks/agentchat_RetrieveChat_qdrant">Using RetrieveChat with Qdrant for Retrieve Augmented Code Generation and Question Answering</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/autogen/docs/notebooks/agentchat_agentops">Agent Tracking with AgentOps</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/autogen/docs/notebooks/agentchat_agentoptimizer">AgentOptimizer: An Agentic Way to Train Your LLM Agent</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/autogen/docs/notebooks/agentchat_auto_feedback_from_code_execution">Task Solving with Code Generation, Execution and Debugging</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/autogen/docs/notebooks/agentchat_azr_ai_search">Assistants with Azure Cognitive Search and Azure Identity</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/autogen/docs/notebooks/agentchat_custom_model">Agent Chat with custom model loading</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/autogen/docs/notebooks/agentchat_databricks_dbrx">Use AutoGen in Databricks with DBRX</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/autogen/docs/notebooks/agentchat_function_call_async">Task Solving with Provided Tools as Functions (Asynchronous Function Calls)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/autogen/docs/notebooks/agentchat_function_call_code_writing">Writing a software application using function calls</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/autogen/docs/notebooks/agentchat_function_call_currency_calculator">Currency Calculator: Task Solving with Provided Tools as Functions</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/autogen/docs/notebooks/agentchat_group_chat_with_llamaindex_agents">Groupchat with Llamaindex agents</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/autogen/docs/notebooks/agentchat_groupchat">Group Chat</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/autogen/docs/notebooks/agentchat_groupchat_RAG">Group Chat with Retrieval Augmented Generation</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/autogen/docs/notebooks/agentchat_groupchat_customized">Group Chat with Customized Speaker Selection Method</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/autogen/docs/notebooks/agentchat_groupchat_finite_state_machine">FSM - User can input speaker transition constraints</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/autogen/docs/notebooks/agentchat_groupchat_research">Perform Research with Multi-Agent Group Chat</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/autogen/docs/notebooks/agentchat_groupchat_stateflow">StateFlow: Build Workflows through State-Oriented Actions</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/autogen/docs/notebooks/agentchat_groupchat_vis">Group Chat with Coder and Visualization Critic</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/autogen/docs/notebooks/agentchat_image_generation_capability">Generate Dalle Images With Conversable Agents</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/autogen/docs/notebooks/agentchat_lmm_gpt-4v">Engaging with Multimodal Models: GPT-4V in AutoGen</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/autogen/docs/notebooks/agentchat_logging">Runtime Logging with AutoGen</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/autogen/docs/notebooks/agentchat_multi_task_async_chats">Solving Multiple Tasks in a Sequence of Async Chats</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/autogen/docs/notebooks/agentchat_multi_task_chats">Solving Multiple Tasks in a Sequence of Chats</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/autogen/docs/notebooks/agentchat_nested_chats_chess">Nested Chats for Tool Use in Conversational Chess</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/autogen/docs/notebooks/agentchat_nested_chats_chess_altmodels">Conversational Chess using non-OpenAI clients</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/autogen/docs/notebooks/agentchat_nested_sequential_chats">Solving Complex Tasks with A Sequence of Nested Chats</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/autogen/docs/notebooks/agentchat_nestedchat">Solving Complex Tasks with Nested Chats</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/autogen/docs/notebooks/agentchat_nestedchat_optiguide">OptiGuide with Nested Chats in AutoGen</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/autogen/docs/notebooks/agentchat_oai_assistant_function_call">Chat with OpenAI Assistant using function call in AutoGen: OSS Insights for Advanced GitHub Data Analysis</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/autogen/docs/notebooks/agentchat_oai_assistant_groupchat">Auto Generated Agent Chat: Group Chat with GPTAssistantAgent</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/autogen/docs/notebooks/agentchat_oai_code_interpreter">Auto Generated Agent Chat: GPTAssistant with Code Interpreter</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/autogen/docs/notebooks/agentchat_society_of_mind">SocietyOfMindAgent</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/autogen/docs/notebooks/agentchat_teachability">Chatting with a teachable agent</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/autogen/docs/notebooks/agentchat_teaching">Auto Generated Agent Chat: Teaching</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/autogen/docs/notebooks/agentchat_transform_messages">Preprocessing Chat History with `TransformMessages`</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/autogen/docs/notebooks/agentchat_video_transcript_translate_with_whisper">Translating Video audio using Whisper and GPT-3.5-turbo</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/autogen/docs/notebooks/agentchat_webscraping_with_apify">Web Scraping using Apify Tools</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/autogen/docs/notebooks/agentchat_websockets">Websockets: Streaming input and output using websockets</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/autogen/docs/notebooks/agentchats_sequential_chats">Solving Multiple Tasks in a Sequence of Chats with Different Conversable Agent Pairs</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/autogen/docs/notebooks/gpt_assistant_agent_function_call">From Dad Jokes To Sad Jokes: Function Calling with GPTAssistantAgent</a></li></ul></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/autogen/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/autogen/docs/notebooks"><span itemprop="name">Notebooks</span></a><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Using RetrieveChat with Qdrant for Retrieve Augmented Code Generation and Question Answering</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>Using RetrieveChat with Qdrant for Retrieve Augmented Code Generation and Question Answering</h1>
<p><a href="https://colab.research.google.com/github/microsoft/autogen/blob/main/notebook/agentchat_RetrieveChat_qdrant.ipynb" target="_blank" rel="noopener noreferrer"><img decoding="async" loading="lazy" src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" class="img_ev3q"></a>
<a href="https://github.com/microsoft/autogen/blob/main/notebook/agentchat_RetrieveChat_qdrant.ipynb" target="_blank" rel="noopener noreferrer"><img decoding="async" loading="lazy" src="https://img.shields.io/badge/Open%20on%20GitHub-grey?logo=github" alt="Open on GitHub" class="img_ev3q"></a></p>
<p><a href="https://qdrant.tech/" target="_blank" rel="noopener noreferrer">Qdrant</a> is a high-performance vector search
engine/database.</p>
<p>This notebook demonstrates the usage of Qdrant for RAG, based on
<a href="https://colab.research.google.com/github/microsoft/autogen/blob/main/notebook/agentchat_RetrieveChat.ipynb" target="_blank" rel="noopener noreferrer">agentchat_RetrieveChat.ipynb</a>.</p>
<p>RetrieveChat is a conversational system for retrieve augmented code
generation and question answering. In this notebook, we demonstrate how
to utilize RetrieveChat to generate code and answer questions based on
customized documentations that are not present in the LLM’s training
dataset. RetrieveChat uses the <code>AssistantAgent</code> and
<code>RetrieveUserProxyAgent</code>, which is similar to the usage of
<code>AssistantAgent</code> and <code>UserProxyAgent</code> in other notebooks (e.g.,
<a href="https://github.com/microsoft/autogen/blob/main/notebook/agentchat_auto_feedback_from_code_execution.ipynb" target="_blank" rel="noopener noreferrer">Automated Task Solving with Code Generation, Execution &amp;
Debugging</a>).</p>
<p>We’ll demonstrate usage of RetrieveChat with Qdrant for code generation
and question answering w/ human feedback.</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>Requirements</div><div class="admonitionContent_BuS1"><p>Some extra dependencies are needed for this notebook, which can be installed via pip:</p><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">pip install &quot;pyautogen[retrievechat-qdrant]&quot; &quot;flaml[automl]&quot;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>For more information, please refer to the <a href="/autogen/docs/installation/">installation guide</a>.</p></div></div>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token operator" style="color:rgb(137, 221, 255)">%</span><span class="token plain">pip install </span><span class="token string" style="color:rgb(195, 232, 141)">&quot;pyautogen[retrievechat-qdrant]&quot;</span><span class="token plain"> </span><span class="token string" style="color:rgb(195, 232, 141)">&quot;flaml[automl]&quot;</span><span class="token plain"> </span><span class="token operator" style="color:rgb(137, 221, 255)">-</span><span class="token plain">q</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">Note: you may need to restart the kernel to use updated packages.</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="set-your-api-endpoint">Set your API Endpoint<a href="#set-your-api-endpoint" class="hash-link" aria-label="Direct link to Set your API Endpoint" title="Direct link to Set your API Endpoint">​</a></h2>
<p>The
<a href="https://microsoft.github.io/autogen/docs/reference/oai/openai_utils#config_list_from_json" target="_blank" rel="noopener noreferrer"><code>config_list_from_json</code></a>
function loads a list of configurations from an environment variable or
a json file.</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token keyword" style="font-style:italic">from</span><span class="token plain"> qdrant_client </span><span class="token keyword" style="font-style:italic">import</span><span class="token plain"> QdrantClient</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token keyword" style="font-style:italic">from</span><span class="token plain"> sentence_transformers </span><span class="token keyword" style="font-style:italic">import</span><span class="token plain"> SentenceTransformer</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token keyword" style="font-style:italic">import</span><span class="token plain"> autogen</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token keyword" style="font-style:italic">from</span><span class="token plain"> autogen </span><span class="token keyword" style="font-style:italic">import</span><span class="token plain"> AssistantAgent</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token keyword" style="font-style:italic">from</span><span class="token plain"> autogen</span><span class="token punctuation" style="color:rgb(199, 146, 234)">.</span><span class="token plain">agentchat</span><span class="token punctuation" style="color:rgb(199, 146, 234)">.</span><span class="token plain">contrib</span><span class="token punctuation" style="color:rgb(199, 146, 234)">.</span><span class="token plain">retrieve_user_proxy_agent </span><span class="token keyword" style="font-style:italic">import</span><span class="token plain"> RetrieveUserProxyAgent</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token comment" style="color:rgb(105, 112, 152);font-style:italic"># Accepted file formats for that can be stored in</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token comment" style="color:rgb(105, 112, 152);font-style:italic"># a vector database instance</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token keyword" style="font-style:italic">from</span><span class="token plain"> autogen</span><span class="token punctuation" style="color:rgb(199, 146, 234)">.</span><span class="token plain">retrieve_utils </span><span class="token keyword" style="font-style:italic">import</span><span class="token plain"> TEXT_FORMATS</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">config_list </span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain"> autogen</span><span class="token punctuation" style="color:rgb(199, 146, 234)">.</span><span class="token plain">config_list_from_json</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token string" style="color:rgb(195, 232, 141)">&quot;OAI_CONFIG_LIST&quot;</span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token keyword" style="font-style:italic">assert</span><span class="token plain"> </span><span class="token builtin" style="color:rgb(130, 170, 255)">len</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token plain">config_list</span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token plain"> </span><span class="token operator" style="color:rgb(137, 221, 255)">&gt;</span><span class="token plain"> </span><span class="token number" style="color:rgb(247, 140, 108)">0</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token keyword" style="font-style:italic">print</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token string" style="color:rgb(195, 232, 141)">&quot;models to use: &quot;</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(199, 146, 234)">[</span><span class="token plain">config_list</span><span class="token punctuation" style="color:rgb(199, 146, 234)">[</span><span class="token plain">i</span><span class="token punctuation" style="color:rgb(199, 146, 234)">]</span><span class="token punctuation" style="color:rgb(199, 146, 234)">[</span><span class="token string" style="color:rgb(195, 232, 141)">&quot;model&quot;</span><span class="token punctuation" style="color:rgb(199, 146, 234)">]</span><span class="token plain"> </span><span class="token keyword" style="font-style:italic">for</span><span class="token plain"> i </span><span class="token keyword" style="font-style:italic">in</span><span class="token plain"> </span><span class="token builtin" style="color:rgb(130, 170, 255)">range</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token builtin" style="color:rgb(130, 170, 255)">len</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token plain">config_list</span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token punctuation" style="color:rgb(199, 146, 234)">]</span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">models to use:  [&#x27;gpt4-1106-preview&#x27;, &#x27;gpt-4o&#x27;, &#x27;gpt-35-turbo&#x27;, &#x27;gpt-35-turbo-0613&#x27;]</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>tip</div><div class="admonitionContent_BuS1"><p>Learn more about configuring LLMs for agents <a href="/autogen/docs/topics/llm_configuration">here</a>.</p></div></div>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token keyword" style="font-style:italic">print</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token string" style="color:rgb(195, 232, 141)">&quot;Accepted file formats for `docs_path`:&quot;</span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token keyword" style="font-style:italic">print</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token plain">TEXT_FORMATS</span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">Accepted file formats for `docs_path`:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">[&#x27;rtf&#x27;, &#x27;jsonl&#x27;, &#x27;xml&#x27;, &#x27;json&#x27;, &#x27;md&#x27;, &#x27;rst&#x27;, &#x27;docx&#x27;, &#x27;msg&#x27;, &#x27;pdf&#x27;, &#x27;log&#x27;, &#x27;xlsx&#x27;, &#x27;org&#x27;, &#x27;txt&#x27;, &#x27;csv&#x27;, &#x27;pptx&#x27;, &#x27;tsv&#x27;, &#x27;yml&#x27;, &#x27;epub&#x27;, &#x27;yaml&#x27;, &#x27;ppt&#x27;, &#x27;htm&#x27;, &#x27;doc&#x27;, &#x27;odt&#x27;, &#x27;html&#x27;]</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="construct-agents-for-retrievechat">Construct agents for RetrieveChat<a href="#construct-agents-for-retrievechat" class="hash-link" aria-label="Direct link to Construct agents for RetrieveChat" title="Direct link to Construct agents for RetrieveChat">​</a></h2>
<p>We start by initializing the <code>AssistantAgent</code> and
<code>RetrieveUserProxyAgent</code>. The system message needs to be set to “You are
a helpful assistant.” for AssistantAgent. The detailed instructions are
given in the user message. Later we will use the
<code>RetrieveUserProxyAgent.generate_init_prompt</code> to combine the
instructions and a retrieval augmented generation task for an initial
prompt to be sent to the LLM assistant.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="you-can-find-the-list-of-all-the-embedding-models-supported-by-qdrant-here.">You can find the list of all the embedding models supported by Qdrant <a href="https://qdrant.github.io/fastembed/examples/Supported_Models/" target="_blank" rel="noopener noreferrer">here</a>.<a href="#you-can-find-the-list-of-all-the-embedding-models-supported-by-qdrant-here." class="hash-link" aria-label="Direct link to you-can-find-the-list-of-all-the-embedding-models-supported-by-qdrant-here." title="Direct link to you-can-find-the-list-of-all-the-embedding-models-supported-by-qdrant-here.">​</a></h3>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token comment" style="color:rgb(105, 112, 152);font-style:italic"># 1. create an AssistantAgent instance named &quot;assistant&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">assistant </span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain"> AssistantAgent</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    name</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token string" style="color:rgb(195, 232, 141)">&quot;assistant&quot;</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    system_message</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token string" style="color:rgb(195, 232, 141)">&quot;You are a helpful assistant.&quot;</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    llm_config</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token punctuation" style="color:rgb(199, 146, 234)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        </span><span class="token string" style="color:rgb(195, 232, 141)">&quot;timeout&quot;</span><span class="token punctuation" style="color:rgb(199, 146, 234)">:</span><span class="token plain"> </span><span class="token number" style="color:rgb(247, 140, 108)">600</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        </span><span class="token string" style="color:rgb(195, 232, 141)">&quot;cache_seed&quot;</span><span class="token punctuation" style="color:rgb(199, 146, 234)">:</span><span class="token plain"> </span><span class="token number" style="color:rgb(247, 140, 108)">42</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        </span><span class="token string" style="color:rgb(195, 232, 141)">&quot;config_list&quot;</span><span class="token punctuation" style="color:rgb(199, 146, 234)">:</span><span class="token plain"> config_list</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(199, 146, 234)">}</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token comment" style="color:rgb(105, 112, 152);font-style:italic"># Optionally create embedding function object</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">sentence_transformer_ef </span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain"> SentenceTransformer</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token string" style="color:rgb(195, 232, 141)">&quot;all-distilroberta-v1&quot;</span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token punctuation" style="color:rgb(199, 146, 234)">.</span><span class="token plain">encode</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">client </span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain"> QdrantClient</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token string" style="color:rgb(195, 232, 141)">&quot;:memory:&quot;</span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token comment" style="color:rgb(105, 112, 152);font-style:italic"># 2. create the RetrieveUserProxyAgent instance named &quot;ragproxyagent&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token comment" style="color:rgb(105, 112, 152);font-style:italic"># Refer to https://microsoft.github.io/autogen/docs/reference/agentchat/contrib/retrieve_user_proxy_agent</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token comment" style="color:rgb(105, 112, 152);font-style:italic"># and https://microsoft.github.io/autogen/docs/reference/agentchat/contrib/vectordb/qdrant</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token comment" style="color:rgb(105, 112, 152);font-style:italic"># for more information on the RetrieveUserProxyAgent and QdrantVectorDB</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">ragproxyagent </span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain"> RetrieveUserProxyAgent</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    name</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token string" style="color:rgb(195, 232, 141)">&quot;ragproxyagent&quot;</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    human_input_mode</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token string" style="color:rgb(195, 232, 141)">&quot;NEVER&quot;</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    max_consecutive_auto_reply</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token number" style="color:rgb(247, 140, 108)">10</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    retrieve_config</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token punctuation" style="color:rgb(199, 146, 234)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        </span><span class="token string" style="color:rgb(195, 232, 141)">&quot;task&quot;</span><span class="token punctuation" style="color:rgb(199, 146, 234)">:</span><span class="token plain"> </span><span class="token string" style="color:rgb(195, 232, 141)">&quot;code&quot;</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        </span><span class="token string" style="color:rgb(195, 232, 141)">&quot;docs_path&quot;</span><span class="token punctuation" style="color:rgb(199, 146, 234)">:</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(199, 146, 234)">[</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            </span><span class="token string" style="color:rgb(195, 232, 141)">&quot;https://raw.githubusercontent.com/microsoft/flaml/main/README.md&quot;</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            </span><span class="token string" style="color:rgb(195, 232, 141)">&quot;https://raw.githubusercontent.com/microsoft/FLAML/main/website/docs/Research.md&quot;</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        </span><span class="token punctuation" style="color:rgb(199, 146, 234)">]</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain">  </span><span class="token comment" style="color:rgb(105, 112, 152);font-style:italic"># change this to your own path, such as https://raw.githubusercontent.com/microsoft/autogen/main/README.md</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        </span><span class="token string" style="color:rgb(195, 232, 141)">&quot;chunk_token_size&quot;</span><span class="token punctuation" style="color:rgb(199, 146, 234)">:</span><span class="token plain"> </span><span class="token number" style="color:rgb(247, 140, 108)">2000</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        </span><span class="token string" style="color:rgb(195, 232, 141)">&quot;model&quot;</span><span class="token punctuation" style="color:rgb(199, 146, 234)">:</span><span class="token plain"> config_list</span><span class="token punctuation" style="color:rgb(199, 146, 234)">[</span><span class="token number" style="color:rgb(247, 140, 108)">0</span><span class="token punctuation" style="color:rgb(199, 146, 234)">]</span><span class="token punctuation" style="color:rgb(199, 146, 234)">[</span><span class="token string" style="color:rgb(195, 232, 141)">&quot;model&quot;</span><span class="token punctuation" style="color:rgb(199, 146, 234)">]</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        </span><span class="token string" style="color:rgb(195, 232, 141)">&quot;db_config&quot;</span><span class="token punctuation" style="color:rgb(199, 146, 234)">:</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(199, 146, 234)">{</span><span class="token string" style="color:rgb(195, 232, 141)">&quot;client&quot;</span><span class="token punctuation" style="color:rgb(199, 146, 234)">:</span><span class="token plain"> client</span><span class="token punctuation" style="color:rgb(199, 146, 234)">}</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        </span><span class="token string" style="color:rgb(195, 232, 141)">&quot;vector_db&quot;</span><span class="token punctuation" style="color:rgb(199, 146, 234)">:</span><span class="token plain"> </span><span class="token string" style="color:rgb(195, 232, 141)">&quot;qdrant&quot;</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain">  </span><span class="token comment" style="color:rgb(105, 112, 152);font-style:italic"># qdrant database</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        </span><span class="token string" style="color:rgb(195, 232, 141)">&quot;get_or_create&quot;</span><span class="token punctuation" style="color:rgb(199, 146, 234)">:</span><span class="token plain"> </span><span class="token boolean" style="color:rgb(255, 88, 116)">True</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain">  </span><span class="token comment" style="color:rgb(105, 112, 152);font-style:italic"># set to False if you don&#x27;t want to reuse an existing collection</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        </span><span class="token string" style="color:rgb(195, 232, 141)">&quot;overwrite&quot;</span><span class="token punctuation" style="color:rgb(199, 146, 234)">:</span><span class="token plain"> </span><span class="token boolean" style="color:rgb(255, 88, 116)">True</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain">  </span><span class="token comment" style="color:rgb(105, 112, 152);font-style:italic"># set to True if you want to overwrite an existing collection</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        </span><span class="token string" style="color:rgb(195, 232, 141)">&quot;embedding_function&quot;</span><span class="token punctuation" style="color:rgb(199, 146, 234)">:</span><span class="token plain"> sentence_transformer_ef</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain">  </span><span class="token comment" style="color:rgb(105, 112, 152);font-style:italic"># If left out fastembed &quot;BAAI/bge-small-en-v1.5&quot; will be used</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(199, 146, 234)">}</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    code_execution_config</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token boolean" style="color:rgb(255, 88, 116)">False</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">Fetching 5 files:   0%|          | 0/5 [00:00&lt;?, ?it/s]</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p><a id="example-1"></a> ### Example 1</p>
<p><a href="#toc">back to top</a></p>
<p>Use RetrieveChat to answer a question and ask for human-in-loop
feedbacks.</p>
<p>Problem: Is there a function named <code>tune_automl</code> in FLAML?</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token comment" style="color:rgb(105, 112, 152);font-style:italic"># reset the assistant. Always reset the assistant before starting a new conversation.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">assistant</span><span class="token punctuation" style="color:rgb(199, 146, 234)">.</span><span class="token plain">reset</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">qa_problem </span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(195, 232, 141)">&quot;Is there a function called tune_automl?&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">chat_results </span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain"> ragproxyagent</span><span class="token punctuation" style="color:rgb(199, 146, 234)">.</span><span class="token plain">initiate_chat</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token plain">assistant</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"> message</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain">ragproxyagent</span><span class="token punctuation" style="color:rgb(199, 146, 234)">.</span><span class="token plain">message_generator</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"> problem</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain">qa_problem</span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">Trying to create collection.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">VectorDB returns doc_ids:  [[&#x27;987f060a-4399-b91a-0e51-51b6165ea5bb&#x27;, &#x27;0ecd7192-3761-7d6f-9151-5ff504ca740b&#x27;, &#x27;ddbaaafc-abdd-30b4-eecd-ec2c32818952&#x27;]]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">Adding content of doc 987f060a-4399-b91a-0e51-51b6165ea5bb to context.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token message-id class-name" style="color:rgb(255, 203, 107)">ragproxyagent</span><span class="token message-id"> </span><span class="token message-id punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token message-id keyword" style="font-style:italic">to</span><span class="token message-id"> </span><span class="token message-id class-name" style="color:rgb(255, 203, 107)">assistant</span><span class="token message-id punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token message-id">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">You&#x27;re a retrieve augmented coding assistant. You answer user&#x27;s questions based on your own knowledge and the</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">context provided by the user.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">If you can&#x27;t answer the question with or without the current context, you should reply exactly `UPDATE CONTEXT`.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">For code generation, you must obey the following rules:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">Rule 1. You MUST NOT install any packages because all the packages needed are already installed.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">Rule 2. You must follow the formats below to write your code:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```language</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># your code</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">User&#x27;s question is: Is there a function called tune_automl?</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">Context is: [![PyPI version](https://badge.fury.io/py/FLAML.svg)](https://badge.fury.io/py/FLAML)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">![Conda version](https://img.shields.io/conda/vn/conda-forge/flaml)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">[![Build](https://github.com/microsoft/FLAML/actions/workflows/python-package.yml/badge.svg)](https://github.com/microsoft/FLAML/actions/workflows/python-package.yml)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">![Python Version](https://img.shields.io/badge/3.8%20%7C%203.9%20%7C%203.10-blue)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">[![Downloads](https://pepy.tech/badge/flaml)](https://pepy.tech/project/flaml)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">[![](https://img.shields.io/discord/1025786666260111483?logo=discord&amp;style=flat)](https://discord.gg/Cppx2vSPVP)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">&lt;!-- [![Join the chat at https://gitter.im/FLAMLer/community](https://badges.gitter.im/FLAMLer/community.svg)](https://gitter.im/FLAMLer/community?utm_source=badge&amp;utm_medium=badge&amp;utm_campaign=pr-badge&amp;utm_content=badge) --&gt;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># A Fast Library for Automated Machine Learning &amp; Tuning</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">&lt;p align=&quot;center&quot;&gt;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &lt;img src=&quot;https://github.com/microsoft/FLAML/blob/main/website/static/img/flaml.svg&quot;  width=200&gt;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &lt;br&gt;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">&lt;/p&gt;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">:fire: Heads-up: We have migrated [AutoGen](https://microsoft.github.io/autogen/) into a dedicated [github repository](https://github.com/microsoft/autogen). Alongside this move, we have also launched a dedicated [Discord](https://discord.gg/pAbnFJrkgZ) server and a [website](https://microsoft.github.io/autogen/) for comprehensive documentation.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">:fire: The automated multi-agent chat framework in [AutoGen](https://microsoft.github.io/autogen/) is in preview from v2.0.0.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">:fire: FLAML is highlighted in OpenAI&#x27;s [cookbook](https://github.com/openai/openai-cookbook#related-resources-from-around-the-web).</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">:fire: [autogen](https://microsoft.github.io/autogen/) is released with support for ChatGPT and GPT-4, based on [Cost-Effective Hyperparameter Optimization for Large Language Model Generation Inference](https://arxiv.org/abs/2303.04673).</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">:fire: FLAML supports Code-First AutoML &amp; Tuning – Private Preview in [Microsoft Fabric Data Science](https://learn.microsoft.com/en-us/fabric/data-science/).</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">## What is FLAML</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">FLAML is a lightweight Python library for efficient automation of machine</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">learning and AI operations. It automates workflow based on large language models, machine learning models, etc.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">and optimizes their performance.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">- FLAML enables building next-gen GPT-X applications based on multi-agent conversations with minimal effort. It simplifies the orchestration, automation and optimization of a complex GPT-X workflow. It maximizes the performance of GPT-X models and augments their weakness.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">- For common machine learning tasks like classification and regression, it quickly finds quality models for user-provided data with low computational resources. It is easy to customize or extend. Users can find their desired customizability from a smooth range.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">- It supports fast and economical automatic tuning (e.g., inference hyperparameters for foundation models, configurations in MLOps/LMOps workflows, pipelines, mathematical/statistical models, algorithms, computing experiments, software configurations), capable of handling large search space with heterogeneous evaluation cost and complex constraints/guidance/early stopping.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">FLAML is powered by a series of [research studies](https://microsoft.github.io/FLAML/docs/Research/) from Microsoft Research and collaborators such as Penn State University, Stevens Institute of Technology, University of Washington, and University of Waterloo.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">FLAML has a .NET implementation in [ML.NET](http://dot.net/ml), an open-source, cross-platform machine learning framework for .NET.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">## Installation</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">FLAML requires **Python version &gt;= 3.8**. It can be installed from pip:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```bash</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">pip install flaml</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">Minimal dependencies are installed without extra options. You can install extra options based on the feature you need. For example, use the following to install the dependencies needed by the [`autogen`](https://microsoft.github.io/autogen/) package.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```bash</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">pip install &quot;flaml[autogen]&quot;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">Find more options in [Installation](https://microsoft.github.io/FLAML/docs/Installation).</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">Each of the [`notebook examples`](https://github.com/microsoft/FLAML/tree/main/notebook) may require a specific option to be installed.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">## Quickstart</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">- (New) The [autogen](https://microsoft.github.io/autogen/) package enables the next-gen GPT-X applications with a generic multi-agent conversation framework.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  It offers customizable and conversable agents which integrate LLMs, tools and human.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  By automating chat among multiple capable agents, one can easily make them collectively perform tasks autonomously or with human feedback, including tasks that require using tools via code. For example,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```python</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">from flaml import autogen</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">assistant = autogen.AssistantAgent(&quot;assistant&quot;)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">user_proxy = autogen.UserProxyAgent(&quot;user_proxy&quot;)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">user_proxy.initiate_chat(</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    assistant,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    message=&quot;Show me the YTD gain of 10 largest technology companies as of today.&quot;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># This initiates an automated chat between the two agents to solve the task</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">Autogen also helps maximize the utility out of the expensive LLMs such as ChatGPT and GPT-4. It offers a drop-in replacement of `openai.Completion` or `openai.ChatCompletion` with powerful functionalites like tuning, caching, templating, filtering. For example, you can optimize generations by LLM with your own tuning data, success metrics and budgets.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```python</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># perform tuning</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">config, analysis = autogen.Completion.tune(</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    data=tune_data,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    metric=&quot;success&quot;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    mode=&quot;max&quot;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    eval_func=eval_func,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    inference_budget=0.05,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    optimization_budget=3,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    num_samples=-1,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># perform inference for a test instance</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">response = autogen.Completion.create(context=test_instance, **config)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">- With three lines of code, you can start using this economical and fast</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  AutoML engine as a [scikit-learn style estimator](https://microsoft.github.io/FLAML/docs/Use-Cases/Task-Oriented-AutoML).</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```python</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">from flaml import AutoML</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">automl = AutoML()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">automl.fit(X_train, y_train, task=&quot;classification&quot;)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">- You can restrict the learners and use FLAML as a fast hyperparameter tuning</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  tool for XGBoost, LightGBM, Random Forest etc. or a [customized learner](https://microsoft.github.io/FLAML/docs/Use-Cases/Task-Oriented-AutoML#estimator-and-search-space).</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```python</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">automl.fit(X_train, y_train, task=&quot;classification&quot;, estimator_list=[&quot;lgbm&quot;])</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">- You can also run generic hyperparameter tuning for a [custom function](https://microsoft.github.io/FLAML/docs/Use-Cases/Tune-User-Defined-Function).</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```python</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">from flaml import tune</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">tune.run(evaluation_function, config={…}, low_cost_partial_config={…}, time_budget_s=3600)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">- [Zero-shot AutoML](https://microsoft.github.io/FLAML/docs/Use-Cases/Zero-Shot-AutoML) allows using the existing training API from lightgbm, xgboost etc. while getting the benefit of AutoML in choosing high-performance hyperparameter configurations per task.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```python</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">from flaml.default import LGBMRegressor</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Use LGBMRegressor in the same way as you use lightgbm.LGBMRegressor.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">estimator = LGBMRegressor()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># The hyperparameters are automatically set according to the training data.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">estimator.fit(X_train, y_train)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">## Documentation</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">You can find a detailed documentation about FLAML [here](https://microsoft.github.io/FLAML/).</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">In addition, you can find:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">- [Research](https://microsoft.github.io/FLAML/docs/Research) and [blogposts](https://microsoft.github.io/FLAML/blog) around FLAML.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">- [Discord](https://discord.gg/Cppx2vSPVP).</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">- [Contributing guide](https://microsoft.github.io/FLAML/docs/Contribute).</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">- ML.NET documentation and tutorials for [Model Builder](https://learn.microsoft.com/dotnet/machine-learning/tutorials/predict-prices-with-model-builder), [ML.NET CLI](https://learn.microsoft.com/dotnet/machine-learning/tutorials/sentiment-analysis-cli), and [AutoML API](https://learn.microsoft.com/dotnet/machine-learning/how-to-guides/how-to-use-the-automl-api).</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">## Contributing</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">This project welcomes contributions and suggestions. Most contributions require you to agree to a</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">the rights to use your contribution. For details, visit &lt;https://cla.opensource.microsoft.com&gt;.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token punctuation" style="color:rgb(199, 146, 234)">--------------------------------------------------------------------------------</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token message-id class-name" style="color:rgb(255, 203, 107)">assistant</span><span class="token message-id"> </span><span class="token message-id punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token message-id keyword" style="font-style:italic">to</span><span class="token message-id"> </span><span class="token message-id class-name" style="color:rgb(255, 203, 107)">ragproxyagent</span><span class="token message-id punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token message-id">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">No, there is no function called `tune_automl` specifically mentioned in the context provided. However, FLAML does offer general hyperparameter tuning capabilities which could be related to this. In the context of FLAML, there is a generic function called `tune.run()` that can be used for hyperparameter tuning.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">Here&#x27;s a short example of how to use FLAML&#x27;s tune for a user-defined function based on the given context:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```python</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">from flaml import tune</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">def evaluation_function(config):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # evaluation logic that returns a metric score</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    ...</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># define the search space for hyperparameters</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">config_search_space = {</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &#x27;max_depth&#x27;: tune.randint(lower=3, upper=10),</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &#x27;learning_rate&#x27;: tune.loguniform(lower=1e-4, upper=1e-1),</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">}</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># run hyperparameter tuning</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">tune.run(</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    evaluation_function,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    config=config_search_space,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    low_cost_partial_config={&#x27;max_depth&#x27;: 3},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    time_budget_s=3600</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">Please note that if you are referring to a different kind of function or use case, you might need to specify more details or check the official documentation or source code of the FLAML library.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token punctuation" style="color:rgb(199, 146, 234)">--------------------------------------------------------------------------------</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token message-id class-name" style="color:rgb(255, 203, 107)">ragproxyagent</span><span class="token message-id"> </span><span class="token message-id punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token message-id keyword" style="font-style:italic">to</span><span class="token message-id"> </span><span class="token message-id class-name" style="color:rgb(255, 203, 107)">assistant</span><span class="token message-id punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token message-id">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token punctuation" style="color:rgb(199, 146, 234)">--------------------------------------------------------------------------------</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token message-id class-name" style="color:rgb(255, 203, 107)">assistant</span><span class="token message-id"> </span><span class="token message-id punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token message-id keyword" style="font-style:italic">to</span><span class="token message-id"> </span><span class="token message-id class-name" style="color:rgb(255, 203, 107)">ragproxyagent</span><span class="token message-id punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token message-id">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">UPDATE CONTEXT</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token punctuation" style="color:rgb(199, 146, 234)">--------------------------------------------------------------------------------</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">Updating context and resetting conversation.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">Adding content of doc 0ecd7192-3761-7d6f-9151-5ff504ca740b to context.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">Adding content of doc ddbaaafc-abdd-30b4-eecd-ec2c32818952 to context.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token message-id class-name" style="color:rgb(255, 203, 107)">ragproxyagent</span><span class="token message-id"> </span><span class="token message-id punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token message-id keyword" style="font-style:italic">to</span><span class="token message-id"> </span><span class="token message-id class-name" style="color:rgb(255, 203, 107)">assistant</span><span class="token message-id punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token message-id">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">You&#x27;re a retrieve augmented coding assistant. You answer user&#x27;s questions based on your own knowledge and the</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">context provided by the user.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">If you can&#x27;t answer the question with or without the current context, you should reply exactly `UPDATE CONTEXT`.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">For code generation, you must obey the following rules:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">Rule 1. You MUST NOT install any packages because all the packages needed are already installed.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">Rule 2. You must follow the formats below to write your code:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```language</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># your code</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">User&#x27;s question is: Is there a function called tune_automl?</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">Context is: # Research</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">For technical details, please check our research publications.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">- [FLAML: A Fast and Lightweight AutoML Library](https://www.microsoft.com/en-us/research/publication/flaml-a-fast-and-lightweight-automl-library/). Chi Wang, Qingyun Wu, Markus Weimer, Erkang Zhu. MLSys 2021.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```bibtex</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">@inproceedings{wang2021flaml,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    title={FLAML: A Fast and Lightweight AutoML Library},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    author={Chi Wang and Qingyun Wu and Markus Weimer and Erkang Zhu},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    year={2021},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    booktitle={MLSys},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">}</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">- [Frugal Optimization for Cost-related Hyperparameters](https://arxiv.org/abs/2005.01571). Qingyun Wu, Chi Wang, Silu Huang. AAAI 2021.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```bibtex</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">@inproceedings{wu2021cfo,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    title={Frugal Optimization for Cost-related Hyperparameters},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    author={Qingyun Wu and Chi Wang and Silu Huang},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    year={2021},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    booktitle={AAAI},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">}</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">- [Economical Hyperparameter Optimization With Blended Search Strategy](https://www.microsoft.com/en-us/research/publication/economical-hyperparameter-optimization-with-blended-search-strategy/). Chi Wang, Qingyun Wu, Silu Huang, Amin Saied. ICLR 2021.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```bibtex</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">@inproceedings{wang2021blendsearch,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    title={Economical Hyperparameter Optimization With Blended Search Strategy},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    author={Chi Wang and Qingyun Wu and Silu Huang and Amin Saied},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    year={2021},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    booktitle={ICLR},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">}</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">- [An Empirical Study on Hyperparameter Optimization for Fine-Tuning Pre-trained Language Models](https://aclanthology.org/2021.acl-long.178.pdf). Susan Xueqing Liu, Chi Wang. ACL 2021.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```bibtex</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">@inproceedings{liuwang2021hpolm,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    title={An Empirical Study on Hyperparameter Optimization for Fine-Tuning Pre-trained Language Models},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    author={Susan Xueqing Liu and Chi Wang},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    year={2021},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    booktitle={ACL},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">}</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">- [ChaCha for Online AutoML](https://www.microsoft.com/en-us/research/publication/chacha-for-online-automl/). Qingyun Wu, Chi Wang, John Langford, Paul Mineiro and Marco Rossi. ICML 2021.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```bibtex</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">@inproceedings{wu2021chacha,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    title={ChaCha for Online AutoML},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    author={Qingyun Wu and Chi Wang and John Langford and Paul Mineiro and Marco Rossi},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    year={2021},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    booktitle={ICML},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">}</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">- [Fair AutoML](https://arxiv.org/abs/2111.06495). Qingyun Wu, Chi Wang. ArXiv preprint arXiv:2111.06495 (2021).</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```bibtex</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">@inproceedings{wuwang2021fairautoml,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    title={Fair AutoML},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    author={Qingyun Wu and Chi Wang},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    year={2021},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    booktitle={ArXiv preprint arXiv:2111.06495},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">}</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">- [Mining Robust Default Configurations for Resource-constrained AutoML](https://arxiv.org/abs/2202.09927). Moe Kayali, Chi Wang. ArXiv preprint arXiv:2202.09927 (2022).</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```bibtex</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">@inproceedings{kayaliwang2022default,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    title={Mining Robust Default Configurations for Resource-constrained AutoML},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    author={Moe Kayali and Chi Wang},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    year={2022},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    booktitle={ArXiv preprint arXiv:2202.09927},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">}</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">- [Targeted Hyperparameter Optimization with Lexicographic Preferences Over Multiple Objectives](https://openreview.net/forum?id=0Ij9_q567Ma). Shaokun Zhang, Feiran Jia, Chi Wang, Qingyun Wu. ICLR 2023 (notable-top-5%).</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```bibtex</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">@inproceedings{zhang2023targeted,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    title={Targeted Hyperparameter Optimization with Lexicographic Preferences Over Multiple Objectives},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    author={Shaokun Zhang and Feiran Jia and Chi Wang and Qingyun Wu},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    booktitle={International Conference on Learning Representations},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    year={2023},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    url={https://openreview.net/forum?id=0Ij9_q567Ma},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">}</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">- [Cost-Effective Hyperparameter Optimization for Large Language Model Generation Inference](https://arxiv.org/abs/2303.04673). Chi Wang, Susan Xueqing Liu, Ahmed H. Awadallah. ArXiv preprint arXiv:2303.04673 (2023).</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```bibtex</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">@inproceedings{wang2023EcoOptiGen,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    title={Cost-Effective Hyperparameter Optimization for Large Language Model Generation Inference},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    author={Chi Wang and Susan Xueqing Liu and Ahmed H. Awadallah},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    year={2023},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    booktitle={ArXiv preprint arXiv:2303.04673},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">}</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">- [An Empirical Study on Challenging Math Problem Solving with GPT-4](https://arxiv.org/abs/2306.01337). Yiran Wu, Feiran Jia, Shaokun Zhang, Hangyu Li, Erkang Zhu, Yue Wang, Yin Tat Lee, Richard Peng, Qingyun Wu, Chi Wang. ArXiv preprint arXiv:2306.01337 (2023).</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```bibtex</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">@inproceedings{wu2023empirical,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    title={An Empirical Study on Challenging Math Problem Solving with GPT-4},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    author={Yiran Wu and Feiran Jia and Shaokun Zhang and Hangyu Li and Erkang Zhu and Yue Wang and Yin Tat Lee and Richard Peng and Qingyun Wu and Chi Wang},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    year={2023},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    booktitle={ArXiv preprint arXiv:2306.01337},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">}</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">If you are new to GitHub [here](https://help.github.com/categories/collaborating-with-issues-and-pull-requests/) is a detailed help source on getting involved with development on GitHub.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">When you submit a pull request, a CLA bot will automatically determine whether you need to provide</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">provided by the bot. You will only need to do this once across all repos using our CLA.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">This project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token message-id class-name" style="color:rgb(255, 203, 107)">ragproxyagent</span><span class="token message-id"> </span><span class="token message-id punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token message-id keyword" style="font-style:italic">to</span><span class="token message-id"> </span><span class="token message-id class-name" style="color:rgb(255, 203, 107)">assistant</span><span class="token message-id punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token message-id">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">You&#x27;re a retrieve augmented coding assistant. You answer user&#x27;s questions based on your own knowledge and the</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">context provided by the user.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">If you can&#x27;t answer the question with or without the current context, you should reply exactly `UPDATE CONTEXT`.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">For code generation, you must obey the following rules:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">Rule 1. You MUST NOT install any packages because all the packages needed are already installed.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">Rule 2. You must follow the formats below to write your code:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```language</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># your code</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">User&#x27;s question is: Is there a function called tune_automl?</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">Context is: # Research</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">For technical details, please check our research publications.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">- [FLAML: A Fast and Lightweight AutoML Library](https://www.microsoft.com/en-us/research/publication/flaml-a-fast-and-lightweight-automl-library/). Chi Wang, Qingyun Wu, Markus Weimer, Erkang Zhu. MLSys 2021.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```bibtex</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">@inproceedings{wang2021flaml,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    title={FLAML: A Fast and Lightweight AutoML Library},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    author={Chi Wang and Qingyun Wu and Markus Weimer and Erkang Zhu},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    year={2021},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    booktitle={MLSys},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">}</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">- [Frugal Optimization for Cost-related Hyperparameters](https://arxiv.org/abs/2005.01571). Qingyun Wu, Chi Wang, Silu Huang. AAAI 2021.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```bibtex</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">@inproceedings{wu2021cfo,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    title={Frugal Optimization for Cost-related Hyperparameters},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    author={Qingyun Wu and Chi Wang and Silu Huang},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    year={2021},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    booktitle={AAAI},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">}</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">- [Economical Hyperparameter Optimization With Blended Search Strategy](https://www.microsoft.com/en-us/research/publication/economical-hyperparameter-optimization-with-blended-search-strategy/). Chi Wang, Qingyun Wu, Silu Huang, Amin Saied. ICLR 2021.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```bibtex</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">@inproceedings{wang2021blendsearch,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    title={Economical Hyperparameter Optimization With Blended Search Strategy},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    author={Chi Wang and Qingyun Wu and Silu Huang and Amin Saied},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    year={2021},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    booktitle={ICLR},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">}</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">- [An Empirical Study on Hyperparameter Optimization for Fine-Tuning Pre-trained Language Models](https://aclanthology.org/2021.acl-long.178.pdf). Susan Xueqing Liu, Chi Wang. ACL 2021.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```bibtex</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">@inproceedings{liuwang2021hpolm,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    title={An Empirical Study on Hyperparameter Optimization for Fine-Tuning Pre-trained Language Models},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    author={Susan Xueqing Liu and Chi Wang},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    year={2021},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    booktitle={ACL},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">}</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">- [ChaCha for Online AutoML](https://www.microsoft.com/en-us/research/publication/chacha-for-online-automl/). Qingyun Wu, Chi Wang, John Langford, Paul Mineiro and Marco Rossi. ICML 2021.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```bibtex</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">@inproceedings{wu2021chacha,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    title={ChaCha for Online AutoML},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    author={Qingyun Wu and Chi Wang and John Langford and Paul Mineiro and Marco Rossi},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    year={2021},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    booktitle={ICML},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">}</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">- [Fair AutoML](https://arxiv.org/abs/2111.06495). Qingyun Wu, Chi Wang. ArXiv preprint arXiv:2111.06495 (2021).</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```bibtex</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">@inproceedings{wuwang2021fairautoml,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    title={Fair AutoML},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    author={Qingyun Wu and Chi Wang},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    year={2021},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    booktitle={ArXiv preprint arXiv:2111.06495},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">}</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">- [Mining Robust Default Configurations for Resource-constrained AutoML](https://arxiv.org/abs/2202.09927). Moe Kayali, Chi Wang. ArXiv preprint arXiv:2202.09927 (2022).</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```bibtex</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">@inproceedings{kayaliwang2022default,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    title={Mining Robust Default Configurations for Resource-constrained AutoML},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    author={Moe Kayali and Chi Wang},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    year={2022},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    booktitle={ArXiv preprint arXiv:2202.09927},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">}</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">- [Targeted Hyperparameter Optimization with Lexicographic Preferences Over Multiple Objectives](https://openreview.net/forum?id=0Ij9_q567Ma). Shaokun Zhang, Feiran Jia, Chi Wang, Qingyun Wu. ICLR 2023 (notable-top-5%).</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```bibtex</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">@inproceedings{zhang2023targeted,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    title={Targeted Hyperparameter Optimization with Lexicographic Preferences Over Multiple Objectives},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    author={Shaokun Zhang and Feiran Jia and Chi Wang and Qingyun Wu},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    booktitle={International Conference on Learning Representations},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    year={2023},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    url={https://openreview.net/forum?id=0Ij9_q567Ma},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">}</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">- [Cost-Effective Hyperparameter Optimization for Large Language Model Generation Inference](https://arxiv.org/abs/2303.04673). Chi Wang, Susan Xueqing Liu, Ahmed H. Awadallah. ArXiv preprint arXiv:2303.04673 (2023).</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```bibtex</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">@inproceedings{wang2023EcoOptiGen,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    title={Cost-Effective Hyperparameter Optimization for Large Language Model Generation Inference},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    author={Chi Wang and Susan Xueqing Liu and Ahmed H. Awadallah},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    year={2023},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    booktitle={ArXiv preprint arXiv:2303.04673},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">}</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">- [An Empirical Study on Challenging Math Problem Solving with GPT-4](https://arxiv.org/abs/2306.01337). Yiran Wu, Feiran Jia, Shaokun Zhang, Hangyu Li, Erkang Zhu, Yue Wang, Yin Tat Lee, Richard Peng, Qingyun Wu, Chi Wang. ArXiv preprint arXiv:2306.01337 (2023).</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```bibtex</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">@inproceedings{wu2023empirical,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    title={An Empirical Study on Challenging Math Problem Solving with GPT-4},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    author={Yiran Wu and Feiran Jia and Shaokun Zhang and Hangyu Li and Erkang Zhu and Yue Wang and Yin Tat Lee and Richard Peng and Qingyun Wu and Chi Wang},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    year={2023},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    booktitle={ArXiv preprint arXiv:2306.01337},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">}</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">If you are new to GitHub [here](https://help.github.com/categories/collaborating-with-issues-and-pull-requests/) is a detailed help source on getting involved with development on GitHub.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">When you submit a pull request, a CLA bot will automatically determine whether you need to provide</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">provided by the bot. You will only need to do this once across all repos using our CLA.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">This project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token punctuation" style="color:rgb(199, 146, 234)">--------------------------------------------------------------------------------</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token message-id class-name" style="color:rgb(255, 203, 107)">assistant</span><span class="token message-id"> </span><span class="token message-id punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token message-id keyword" style="font-style:italic">to</span><span class="token message-id"> </span><span class="token message-id class-name" style="color:rgb(255, 203, 107)">ragproxyagent</span><span class="token message-id punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token message-id">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">UPDATE CONTEXT</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token punctuation" style="color:rgb(199, 146, 234)">--------------------------------------------------------------------------------</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">Updating context and resetting conversation.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">VectorDB returns doc_ids:  [[&#x27;987f060a-4399-b91a-0e51-51b6165ea5bb&#x27;, &#x27;0ecd7192-3761-7d6f-9151-5ff504ca740b&#x27;, &#x27;ddbaaafc-abdd-30b4-eecd-ec2c32818952&#x27;]]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">VectorDB returns doc_ids:  [[&#x27;987f060a-4399-b91a-0e51-51b6165ea5bb&#x27;, &#x27;0ecd7192-3761-7d6f-9151-5ff504ca740b&#x27;, &#x27;ddbaaafc-abdd-30b4-eecd-ec2c32818952&#x27;]]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">VectorDB returns doc_ids:  [[&#x27;987f060a-4399-b91a-0e51-51b6165ea5bb&#x27;, &#x27;0ecd7192-3761-7d6f-9151-5ff504ca740b&#x27;, &#x27;ddbaaafc-abdd-30b4-eecd-ec2c32818952&#x27;]]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">VectorDB returns doc_ids:  [[&#x27;987f060a-4399-b91a-0e51-51b6165ea5bb&#x27;, &#x27;0ecd7192-3761-7d6f-9151-5ff504ca740b&#x27;, &#x27;ddbaaafc-abdd-30b4-eecd-ec2c32818952&#x27;]]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">No more context, will terminate.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token message-id class-name" style="color:rgb(255, 203, 107)">ragproxyagent</span><span class="token message-id"> </span><span class="token message-id punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token message-id keyword" style="font-style:italic">to</span><span class="token message-id"> </span><span class="token message-id class-name" style="color:rgb(255, 203, 107)">assistant</span><span class="token message-id punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token message-id">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token builtin" style="color:rgb(130, 170, 255)">TERMINATE</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token punctuation" style="color:rgb(199, 146, 234)">--------------------------------------------------------------------------------</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">2024-07-15 23:19:34,988 - autogen.agentchat.contrib.retrieve_user_proxy_agent - INFO - Found 3 chunks.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">Model gpt4-1106-preview not found. Using cl100k_base encoding.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">Model gpt4-1106-preview not found. Using cl100k_base encoding.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">Model gpt4-1106-preview not found. Using cl100k_base encoding.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">Model gpt4-1106-preview not found. Using cl100k_base encoding.</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p><a id="example-2"></a> ### Example 2</p>
<p><a href="#toc">back to top</a></p>
<p>Use RetrieveChat to answer a question that is not related to code
generation.</p>
<p>Problem: Who is the author of FLAML?</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token comment" style="color:rgb(105, 112, 152);font-style:italic"># reset the assistant. Always reset the assistant before starting a new conversation.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">assistant</span><span class="token punctuation" style="color:rgb(199, 146, 234)">.</span><span class="token plain">reset</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">qa_problem </span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(195, 232, 141)">&quot;Who is the author of FLAML?&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">chat_results </span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain"> ragproxyagent</span><span class="token punctuation" style="color:rgb(199, 146, 234)">.</span><span class="token plain">initiate_chat</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token plain">assistant</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"> message</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain">ragproxyagent</span><span class="token punctuation" style="color:rgb(199, 146, 234)">.</span><span class="token plain">message_generator</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"> problem</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain">qa_problem</span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">Model gpt4-1106-preview not found. Using cl100k_base encoding.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">Model gpt4-1106-preview not found. Using cl100k_base encoding.</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">VectorDB returns doc_ids:  [[&#x27;0ecd7192-3761-7d6f-9151-5ff504ca740b&#x27;, &#x27;987f060a-4399-b91a-0e51-51b6165ea5bb&#x27;, &#x27;ddbaaafc-abdd-30b4-eecd-ec2c32818952&#x27;]]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">Adding content of doc 0ecd7192-3761-7d6f-9151-5ff504ca740b to context.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token message-id class-name" style="color:rgb(255, 203, 107)">ragproxyagent</span><span class="token message-id"> </span><span class="token message-id punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token message-id keyword" style="font-style:italic">to</span><span class="token message-id"> </span><span class="token message-id class-name" style="color:rgb(255, 203, 107)">assistant</span><span class="token message-id punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token message-id">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">You&#x27;re a retrieve augmented coding assistant. You answer user&#x27;s questions based on your own knowledge and the</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">context provided by the user.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">If you can&#x27;t answer the question with or without the current context, you should reply exactly `UPDATE CONTEXT`.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">For code generation, you must obey the following rules:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">Rule 1. You MUST NOT install any packages because all the packages needed are already installed.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">Rule 2. You must follow the formats below to write your code:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```language</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># your code</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">User&#x27;s question is: Who is the author of FLAML?</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">Context is: # Research</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">For technical details, please check our research publications.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">- [FLAML: A Fast and Lightweight AutoML Library](https://www.microsoft.com/en-us/research/publication/flaml-a-fast-and-lightweight-automl-library/). Chi Wang, Qingyun Wu, Markus Weimer, Erkang Zhu. MLSys 2021.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```bibtex</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">@inproceedings{wang2021flaml,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    title={FLAML: A Fast and Lightweight AutoML Library},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    author={Chi Wang and Qingyun Wu and Markus Weimer and Erkang Zhu},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    year={2021},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    booktitle={MLSys},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">}</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">- [Frugal Optimization for Cost-related Hyperparameters](https://arxiv.org/abs/2005.01571). Qingyun Wu, Chi Wang, Silu Huang. AAAI 2021.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```bibtex</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">@inproceedings{wu2021cfo,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    title={Frugal Optimization for Cost-related Hyperparameters},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    author={Qingyun Wu and Chi Wang and Silu Huang},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    year={2021},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    booktitle={AAAI},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">}</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">- [Economical Hyperparameter Optimization With Blended Search Strategy](https://www.microsoft.com/en-us/research/publication/economical-hyperparameter-optimization-with-blended-search-strategy/). Chi Wang, Qingyun Wu, Silu Huang, Amin Saied. ICLR 2021.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```bibtex</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">@inproceedings{wang2021blendsearch,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    title={Economical Hyperparameter Optimization With Blended Search Strategy},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    author={Chi Wang and Qingyun Wu and Silu Huang and Amin Saied},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    year={2021},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    booktitle={ICLR},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">}</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">- [An Empirical Study on Hyperparameter Optimization for Fine-Tuning Pre-trained Language Models](https://aclanthology.org/2021.acl-long.178.pdf). Susan Xueqing Liu, Chi Wang. ACL 2021.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```bibtex</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">@inproceedings{liuwang2021hpolm,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    title={An Empirical Study on Hyperparameter Optimization for Fine-Tuning Pre-trained Language Models},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    author={Susan Xueqing Liu and Chi Wang},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    year={2021},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    booktitle={ACL},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">}</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">- [ChaCha for Online AutoML](https://www.microsoft.com/en-us/research/publication/chacha-for-online-automl/). Qingyun Wu, Chi Wang, John Langford, Paul Mineiro and Marco Rossi. ICML 2021.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```bibtex</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">@inproceedings{wu2021chacha,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    title={ChaCha for Online AutoML},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    author={Qingyun Wu and Chi Wang and John Langford and Paul Mineiro and Marco Rossi},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    year={2021},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    booktitle={ICML},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">}</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">- [Fair AutoML](https://arxiv.org/abs/2111.06495). Qingyun Wu, Chi Wang. ArXiv preprint arXiv:2111.06495 (2021).</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```bibtex</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">@inproceedings{wuwang2021fairautoml,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    title={Fair AutoML},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    author={Qingyun Wu and Chi Wang},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    year={2021},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    booktitle={ArXiv preprint arXiv:2111.06495},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">}</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">- [Mining Robust Default Configurations for Resource-constrained AutoML](https://arxiv.org/abs/2202.09927). Moe Kayali, Chi Wang. ArXiv preprint arXiv:2202.09927 (2022).</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```bibtex</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">@inproceedings{kayaliwang2022default,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    title={Mining Robust Default Configurations for Resource-constrained AutoML},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    author={Moe Kayali and Chi Wang},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    year={2022},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    booktitle={ArXiv preprint arXiv:2202.09927},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">}</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">- [Targeted Hyperparameter Optimization with Lexicographic Preferences Over Multiple Objectives](https://openreview.net/forum?id=0Ij9_q567Ma). Shaokun Zhang, Feiran Jia, Chi Wang, Qingyun Wu. ICLR 2023 (notable-top-5%).</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```bibtex</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">@inproceedings{zhang2023targeted,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    title={Targeted Hyperparameter Optimization with Lexicographic Preferences Over Multiple Objectives},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    author={Shaokun Zhang and Feiran Jia and Chi Wang and Qingyun Wu},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    booktitle={International Conference on Learning Representations},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    year={2023},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    url={https://openreview.net/forum?id=0Ij9_q567Ma},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">}</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">- [Cost-Effective Hyperparameter Optimization for Large Language Model Generation Inference](https://arxiv.org/abs/2303.04673). Chi Wang, Susan Xueqing Liu, Ahmed H. Awadallah. ArXiv preprint arXiv:2303.04673 (2023).</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```bibtex</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">@inproceedings{wang2023EcoOptiGen,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    title={Cost-Effective Hyperparameter Optimization for Large Language Model Generation Inference},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    author={Chi Wang and Susan Xueqing Liu and Ahmed H. Awadallah},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    year={2023},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    booktitle={ArXiv preprint arXiv:2303.04673},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">}</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">- [An Empirical Study on Challenging Math Problem Solving with GPT-4](https://arxiv.org/abs/2306.01337). Yiran Wu, Feiran Jia, Shaokun Zhang, Hangyu Li, Erkang Zhu, Yue Wang, Yin Tat Lee, Richard Peng, Qingyun Wu, Chi Wang. ArXiv preprint arXiv:2306.01337 (2023).</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```bibtex</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">@inproceedings{wu2023empirical,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    title={An Empirical Study on Challenging Math Problem Solving with GPT-4},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    author={Yiran Wu and Feiran Jia and Shaokun Zhang and Hangyu Li and Erkang Zhu and Yue Wang and Yin Tat Lee and Richard Peng and Qingyun Wu and Chi Wang},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    year={2023},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    booktitle={ArXiv preprint arXiv:2306.01337},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">}</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token punctuation" style="color:rgb(199, 146, 234)">--------------------------------------------------------------------------------</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token message-id class-name" style="color:rgb(255, 203, 107)">assistant</span><span class="token message-id"> </span><span class="token message-id punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token message-id keyword" style="font-style:italic">to</span><span class="token message-id"> </span><span class="token message-id class-name" style="color:rgb(255, 203, 107)">ragproxyagent</span><span class="token message-id punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token message-id">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">The authors of FLAML are Chi Wang, Qingyun Wu, Markus Weimer, and Erkang Zhu.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token punctuation" style="color:rgb(199, 146, 234)">--------------------------------------------------------------------------------</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-tags-row row margin-bottom--sm"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/autogen/docs/tags/rag">rag</a></li></ul></div></div><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/microsoft/autogen/edit/main/notebook/agentchat_RetrieveChat_qdrant.ipynb" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_vwxv"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/autogen/docs/notebooks/agentchat_RetrieveChat_pgvector"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Using RetrieveChat Powered by PGVector for Retrieve Augmented Code Generation and Question Answering</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/autogen/docs/notebooks/agentchat_agentops"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Agent Tracking with AgentOps</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#set-your-api-endpoint" class="table-of-contents__link toc-highlight">Set your API Endpoint</a></li><li><a href="#construct-agents-for-retrievechat" class="table-of-contents__link toc-highlight">Construct agents for RetrieveChat</a><ul><li><a href="#you-can-find-the-list-of-all-the-embedding-models-supported-by-qdrant-here." class="table-of-contents__link toc-highlight">You can find the list of all the embedding models supported by Qdrant here.</a></li></ul></li></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://aka.ms/autogen-dc" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://twitter.com/pyautogen" target="_blank" rel="noopener noreferrer" class="footer__link-item">Twitter<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2024 AutoGen Authors |  <a target="_blank" style="color:#10adff" href="https://go.microsoft.com/fwlink/?LinkId=521839">Privacy and Cookies</a></div></div></div></footer></div>
</body>
</html>